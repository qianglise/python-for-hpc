<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html"><link rel="search" title="Search" href="search.html">
        <link rel="prefetch" href="_static/ENCCS_logo_light.png" as="image">
        <link rel="prefetch" href="_static/ENCCS_logo_dark.png" as="image">

    <link rel="shortcut icon" href="_static/favicon.ico"><!-- Generated with Sphinx 8.2.3 and Furo 2025.09.25 -->
        <title>Your lesson name</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_lesson.css?v=0c089442" />
    <link rel="stylesheet" type="text/css" href="_static/term_role_formatting.css?v=4194e21c" />
    <link rel="stylesheet" type="text/css" href="_static/furo_ext_lesson.css?v=685c8e98" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css?v=a5c4661c" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="_static/overrides.css?v=1c72d2de" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="#"><div class="brand">Your lesson name</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="#">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="_static/ENCCS_logo_light.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="_static/ENCCS_logo_dark.png" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Your lesson name</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-accel-cython">Cython</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-cupy">CuPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-intohpc">Introduction to HPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-mpi4py">Introduction to MPI with Python (mpi4py)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-profile">Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-benchmark">Benchmark</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-quick-reference">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-guide">Instructor’s guide</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="lesson-name">
<h1>LESSON NAME<a class="headerlink" href="#lesson-name" title="Link to this heading">¶</a></h1>
<p>Intro</p>
<div class="admonition-prerequisites prerequisites admonition" id="prerequisites-0">
<p class="admonition-title">Prerequisites</p>
<ul class="simple">
<li><p>FIXME</p></li>
<li><p>…</p></li>
<li><p>…</p></li>
</ul>
</div>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>20 min</p></td>
<td><p><span class="xref std std-doc">filename</span></p></td>
</tr>
</tbody>
</table>
</div>
<div class="toctree-wrapper compound">
<span id="document-accel-cython"></span><section id="cython">
<h2>Cython<a class="headerlink" href="#cython" title="Link to this heading">¶</a></h2>
<p>Cython is a superset of Python that additionally supports calling C functions and  declaring C types on variables and class attributes.
It is also a versatile, general purpose compiler.
Since it is supports a superset of Python syntax, nearly all Python code, including 3rd party Python packages are also valid Cython code.
Under Cython, source code gets translated into optimized C/C++ code and compiled as Python extension modules.</p>
<p>Developers can either:</p>
<ul class="simple">
<li><p>prototype and develop Python code in IPython/Jupyter using the <code class="docutils literal notranslate"><span class="pre">%%cython</span></code> magic command (<strong>easy</strong>), or</p></li>
<li><p>run the <code class="docutils literal notranslate"><span class="pre">cython</span></code> command-line utility to produce a <code class="docutils literal notranslate"><span class="pre">.c</span></code> file from a <code class="docutils literal notranslate"><span class="pre">.py</span></code> or <code class="docutils literal notranslate"><span class="pre">.pyx</span></code> file,
which in turn needs to be compiled with a C compiler to an <code class="docutils literal notranslate"><span class="pre">.so</span></code> library, which can then be directly imported in a Python program (<strong>intermediate</strong>), or</p></li>
<li><p>use <a class="reference external" href="https://setuptools.pypa.io/en/latest/userguide/ext_modules.html">setuptools</a> or <a class="reference external" href="https://mesonbuild.com/Cython.html">meson</a> with <a class="reference external" href="https://mesonbuild.com/meson-python/index.html">meson-python</a> to automate the aforementioned build process (<strong>advanced</strong>).</p></li>
</ul>
<p>Herein, we restrict the discussion to the Jupyter-way of using the <code class="docutils literal notranslate"><span class="pre">%%cython</span></code> magic.
A full overview of Cython capabilities refers to the <a class="reference external" href="https://cython.readthedocs.io/en/latest/">documentation</a>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Due to a <a class="reference external" href="https://github.com/cython/cython/issues/7319">known issue</a> with <code class="docutils literal notranslate"><span class="pre">%%cython</span> <span class="pre">-a</span></code> in <code class="docutils literal notranslate"><span class="pre">jupyter-lab</span></code> we have to use the <code class="docutils literal notranslate"><span class="pre">jupyter-nbclassic</span></code> interface
for this episode.</p>
</div>
<section id="python-baseline-step-0">
<h3>Python: Baseline (step 0)<a class="headerlink" href="#python-baseline-step-0" title="Link to this heading">¶</a></h3>
<div class="admonition-demo-cython demo admonition" id="demo-0">
<p class="admonition-title">Demo: Cython</p>
<p>Consider a problem to integrate a function:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[I = \int^{b}_{a}(x^2 - x)dx\]</div>
</div>
<p>which can be numerically approximated as the following sum:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[I \approx \delta x \sum_{i=0}^{N-1} (x_i^2 - x_i)\]</div>
</div>
<p>where <span class="math notranslate nohighlight">\(a \le x_i \lt b\)</span>, and all <span class="math notranslate nohighlight">\(x_i\)</span> are uniformly spaced apart by <span class="math notranslate nohighlight">\(\delta x = (b - a) / N\)</span>.</p>
<p><strong>Objective</strong>: Repeatedly compute the approximate integral for 1000 different combinations of
<span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(b\)</span> and <span class="math notranslate nohighlight">\(N\)</span>.</p>
</div>
<p>Python code is provided below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="k">def</span><span class="w"> </span><span class="nf">integrate_f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f</span><span class="p">(</span><span class="n">col_a</span><span class="p">,</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">col_N</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<p>We generate a dataframe and apply the <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_integrate_f()</span></code> function on its columns, timing the execution:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>
        <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>
        <span class="s2">&quot;N&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> apply_integrate_f(df[&#39;a&#39;], df[&#39;b&#39;], df[&#39;N&#39;])
<span class="c1"># 101 ms ± 736 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</section>
<section id="cython-benchmarking-step-1">
<h3>Cython: Benchmarking (step 1)<a class="headerlink" href="#cython-benchmarking-step-1" title="Link to this heading">¶</a></h3>
<p>In order to use Cython, we need to import the Cython extension:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> cython
</pre></div>
</div>
<p>As a first cythonization step, we add the cython magic command (<code class="docutils literal notranslate"><span class="pre">%%cython</span> <span class="pre">-a</span></code>) on top of Jupyter code cell.
We start by a simply compiling the Python code using Cython without any changes. The code is shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f_cython_step1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_step1</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step1</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_step1</span><span class="p">(</span><span class="n">col_a</span><span class="p">,</span> <span class="n">col_b</span><span class="p">,</span> <span class="n">col_N</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step1</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
<figure class="align-left" id="id1">
<a class="reference internal image-reference" href="_images/cython_annotate.png"><img alt="The Cython code above is displayed where various lines of the code are highlighted with yellow background colour of varying intensity." src="_images/cython_annotate.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-text">Annotated Cython code obtained by running the code above.
The yellow coloring in the output shows us the amount of pure Python code.</span><a class="headerlink" href="#id1" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>Our task is to remove as much yellow as possible by <em>static typing</em>, <em>i.e.</em> explicitly declaring arguments, parameters, variables and functions.</p>
<p>We benchmark the Python code just using Cython, and it may give either similar or a slight increase in performance.</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython_step1(df[&#39;a&#39;], df[&#39;b&#39;], df[&#39;N&#39;])
<span class="c1"># 102 ms ± 2.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
</section>
<section id="cython-adding-data-type-annotation-to-input-variables-step-2">
<h3>Cython: Adding data type annotation to input variables (step 2)<a class="headerlink" href="#cython-adding-data-type-annotation-to-input-variables-step-2" title="Link to this heading">¶</a></h3>
<p>Now we can start adding data type annotation to the input variables as highlightbed in the code example/cython below:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-UHVyZSBQeXRob24=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tab" tabindex="0">Pure Python</button><button aria-controls="panel-0-Q3l0aG9u" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-Q3l0aG9u" name="Q3l0aG9u" role="tab" tabindex="-1">Cython</button></div><div aria-labelledby="tab-0-UHVyZSBQeXRob24=" class="sphinx-tabs-panel group-tab" id="panel-0-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">cython</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">f_cython_step2</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_step2</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span><span class="p">):</span>   
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step2</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_step2</span><span class="p">(</span>
<span class="hll">    <span class="n">col_a</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
</span><span class="hll">    <span class="n">col_b</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
</span><span class="hll">    <span class="n">col_N</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span><span class="p">[:],</span>
</span><span class="p">):</span>  
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step2</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-Q3l0aG9u" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-Q3l0aG9u" name="Q3l0aG9u" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">f_cython_step2</span><span class="p">(</span><span class="n">double</span> <span class="n">x</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_step2</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">b</span><span class="p">,</span> <span class="n">long</span> <span class="n">N</span><span class="p">):</span>   
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step2</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_step2</span><span class="p">(</span>
<span class="hll">    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_a</span><span class="p">,</span>
</span><span class="hll">    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_b</span><span class="p">,</span>
</span><span class="hll">    <span class="n">long</span><span class="p">[:]</span> <span class="n">col_N</span>
</span><span class="p">):</span>  
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step2</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div></div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="c1"># this will not work</span>
<span class="c1">#%timeit apply_integrate_f_cython_step2(df[&#39;a&#39;], df[&#39;b&#39;], df[&#39;N&#39;])</span>

<span class="c1"># this command works (see the description below)</span>
<span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython_step2(df[&#39;a&#39;].to_numpy(), df[&#39;b&#39;].to_numpy(), df[&#39;N&#39;].to_numpy())
<span class="c1"># 34.3 ms ± 537 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You can not pass a Series directly since Cython definition is specific to an array.
Instead we should use <code class="docutils literal notranslate"><span class="pre">Series.to_numpy()</span></code> to get the underlying NumPy array which works nicely with Cython.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Cython uses the normal C syntax for types and provides all standard ones, including pointers.
Here is a list of some primitive C data types (refer to Cython’s documentation on <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/language_basics.html#types" title="(in Cython v3.2)"><span>Types</span></a>):</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>Cython type identifier</p></td>
<td><p>Pure Python dtype</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">char</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.char</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.int</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">unsigned</span> <span class="pre">int</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.uint</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">long</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.long</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.float</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">double</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.double</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">double</span> <span class="pre">complex</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.doublecomplex</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">size_t</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cython.size_t</span></code></p></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>Using these data types, we can also annotate arrays (see <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/memoryviews.html#memoryviews" title="(in Cython v3.2)"><span>Typed Memoryviews</span></a>):</p>
<ul class="simple">
<li><p>1D <code class="docutils literal notranslate"><span class="pre">np.float64</span></code> array would be equivalent to <code class="docutils literal notranslate"><span class="pre">cython.double[:]</span></code>,</p></li>
<li><p>2D <code class="docutils literal notranslate"><span class="pre">np.float64</span></code> array would be equivalent to <code class="docutils literal notranslate"><span class="pre">cython.double[:,</span> <span class="pre">:]</span></code> and so on…</p></li>
</ul>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>to quote the <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/language_basics.html#language-basics" title="(in Cython v3.2)"><span class="xref std std-ref">Cython documentation</span></a>,</p>
<blockquote>
<div><p><strong>Typing is not a necessity</strong></p>
<p>Providing static typing to parameters and variables is convenience to speed up your code, but it is not a necessity. Optimize where and when needed. In fact,
typing can slow down your code in the case where the typing does not allow optimizations but where Cython still needs to check that the type of some object matches the declared type.</p>
</div></blockquote>
</div>
</section>
<section id="cython-adding-data-type-annotation-to-functions-step-3">
<h3>Cython: Adding data type annotation to functions (step 3)<a class="headerlink" href="#cython-adding-data-type-annotation-to-functions-step-3" title="Link to this heading">¶</a></h3>
<p>Next step, we further add type annotation to functions. There are three ways of declaring functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">def</span></code> - Python style:</p>
<ul>
<li><p>Called by Python or Cython code, and both input/output are Python objects.</p></li>
<li><p>Declaring argument types and local types (thus return values) can allow Cython to generate optimized code which speeds up the execution.</p></li>
<li><p>Once types are declared, a <code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised if the function is passed with the wrong types.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">&#64;cython.cfunc</span></code> or <code class="docutils literal notranslate"><span class="pre">cdef</span></code> - C style:</p>
<ul>
<li><p><a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/language_basics.html#cdef" title="(in Cython v3.2)"><span class="xref std std-ref">cdef</span></a> functions are called from Cython and C, but not from Python code.</p></li>
<li><p>Cython treats functions as pure C functions, which can take any type of arguments, including non-Python types, <cite>e.g.</cite>, pointers.</p></li>
<li><p>This usually gives the <em>best performance</em>.</p></li>
<li><p>However, one should really take care of the functions declared by <code class="docutils literal notranslate"><span class="pre">cdef</span></code> as these functions are actually writing in C.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">&#64;cython.ccall</span></code> or <code class="docutils literal notranslate"><span class="pre">cpdef</span></code> - C/Python mixed style:</p>
<ul>
<li><p><a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/language_basics.html#cpdef" title="(in Cython v3.2)"><span class="xref std std-ref">cpdef</span></a> function combines both <code class="docutils literal notranslate"><span class="pre">cdef</span></code> and <code class="docutils literal notranslate"><span class="pre">def</span></code>.</p></li>
<li><p>Cython will generate a <code class="docutils literal notranslate"><span class="pre">cdef</span></code> function for C types and a <code class="docutils literal notranslate"><span class="pre">def</span></code> function for Python types.</p></li>
<li><p>In terms of performance, <code class="docutils literal notranslate"><span class="pre">cpdef</span></code> functions may be <em>as fast as</em> those using <code class="docutils literal notranslate"><span class="pre">cdef</span></code> and might be as slow as <code class="docutils literal notranslate"><span class="pre">def</span></code> declared functions.</p></li>
</ul>
</li>
</ul>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-UHVyZSBQeXRob24=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tab" tabindex="0">Pure Python</button><button aria-controls="panel-1-Q3l0aG9u" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-Q3l0aG9u" name="Q3l0aG9u" role="tab" tabindex="-1">Cython</button></div><div aria-labelledby="tab-1-UHVyZSBQeXRob24=" class="sphinx-tabs-panel group-tab" id="panel-1-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">cython</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="hll"><span class="nd">@cython</span><span class="o">.</span><span class="n">cfunc</span>
</span><span class="k">def</span><span class="w"> </span><span class="nf">f_cython_step3</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="nd">@cython</span><span class="o">.</span><span class="n">cfunc</span>
</span><span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_step3</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>   
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step3</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="hll"><span class="nd">@cython</span><span class="o">.</span><span class="n">ccall</span>
</span><span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_step3</span><span class="p">(</span>
    <span class="n">col_a</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
    <span class="n">col_b</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
    <span class="n">col_N</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span><span class="p">[:]</span>
<span class="p">):</span>  
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step3</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-Q3l0aG9u" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-Q3l0aG9u" name="Q3l0aG9u" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="hll"><span class="n">cdef</span> <span class="n">f_cython_step3</span><span class="p">(</span><span class="n">double</span> <span class="n">x</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="n">cdef</span> <span class="n">integrate_f_cython_step3</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">b</span><span class="p">,</span> <span class="n">long</span> <span class="n">N</span><span class="p">):</span>   
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step3</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="hll"><span class="n">cpdef</span> <span class="n">apply_integrate_f_cython_step3</span><span class="p">(</span>
</span>    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_a</span><span class="p">,</span>
    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_b</span><span class="p">,</span>
    <span class="n">long</span><span class="p">[:]</span> <span class="n">col_N</span>
<span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step3</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div></div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython_step3(df[&#39;a&#39;].to_numpy(), df[&#39;b&#39;].to_numpy(), df[&#39;N&#39;].to_numpy())
<span class="c1"># 29.2 ms ± 152 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</span>
</pre></div>
</div>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-UHVyZSBQeXRob24=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-2-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tab" tabindex="0">Pure Python</button><button aria-controls="panel-2-Q3l0aG9u" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-Q3l0aG9u" name="Q3l0aG9u" role="tab" tabindex="-1">Cython</button></div><div aria-labelledby="tab-2-UHVyZSBQeXRob24=" class="sphinx-tabs-panel group-tab" id="panel-2-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">cython</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">f_cython_step2</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_step2</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span><span class="p">):</span>   
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step2</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_step2</span><span class="p">(</span>
    <span class="n">col_a</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
    <span class="n">col_b</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
    <span class="n">col_N</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span><span class="p">[:],</span>
<span class="p">):</span>  
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step2</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-Q3l0aG9u" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-Q3l0aG9u" name="Q3l0aG9u" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">f_cython_step2</span><span class="p">(</span><span class="n">double</span> <span class="n">x</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_step2</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">b</span><span class="p">,</span> <span class="n">long</span> <span class="n">N</span><span class="p">):</span>   
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step2</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_step2</span><span class="p">(</span>
    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_a</span><span class="p">,</span>
    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_b</span><span class="p">,</span>
    <span class="n">long</span><span class="p">[:]</span> <span class="n">col_N</span>
<span class="p">):</span>  
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step2</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div></div>
</section>
<section id="cython-adding-data-type-annotation-to-local-variables-and-return-step-4">
<h3>Cython: Adding data type annotation to local variables and return (step 4)<a class="headerlink" href="#cython-adding-data-type-annotation-to-local-variables-and-return-step-4" title="Link to this heading">¶</a></h3>
<p>Last step, we can add type annotation to local variables within functions and the return value.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-UHVyZSBQeXRob24=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-3-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tab" tabindex="0">Pure Python</button><button aria-controls="panel-3-Q3l0aG9u" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-3-Q3l0aG9u" name="Q3l0aG9u" role="tab" tabindex="-1">Cython</button></div><div aria-labelledby="tab-3-UHVyZSBQeXRob24=" class="sphinx-tabs-panel group-tab" id="panel-3-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">cython</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="nd">@cython</span><span class="o">.</span><span class="n">cfunc</span>
<span class="hll"><span class="k">def</span><span class="w"> </span><span class="nf">f_cython_step4</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">:</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="nd">@cython</span><span class="o">.</span><span class="n">cfunc</span>
<span class="k">def</span><span class="w"> </span><span class="nf">integrate_f_cython_step4</span><span class="p">(</span>
    <span class="n">a</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
    <span class="n">N</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span>
<span class="hll"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">:</span>   
</span><span class="hll">    <span class="n">s</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span>
</span><span class="hll">    <span class="n">dx</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span>
</span><span class="hll">    <span class="n">i</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span>
</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step4</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="nd">@cython</span><span class="o">.</span><span class="n">ccall</span>
<span class="k">def</span><span class="w"> </span><span class="nf">apply_integrate_f_cython_step4</span><span class="p">(</span>
    <span class="n">col_a</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
    <span class="n">col_b</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:],</span>
    <span class="n">col_N</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">long</span><span class="p">[:]</span>
<span class="hll"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:]:</span>
</span><span class="hll">    <span class="n">n</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">int</span>
</span><span class="hll">    <span class="n">i</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">int</span>
</span><span class="hll">    <span class="n">res</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:]</span>
</span>    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step4</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-Q3l0aG9u" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-3-Q3l0aG9u" name="Q3l0aG9u" role="tabpanel" tabindex="0"><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">cython</span> <span class="o">-</span><span class="n">a</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="hll"><span class="n">cdef</span> <span class="n">double</span> <span class="n">f_cython_step4</span><span class="p">(</span><span class="n">double</span> <span class="n">x</span><span class="p">):</span>
</span>    <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span>

<span class="hll"><span class="n">cdef</span> <span class="n">double</span> <span class="n">integrate_f_cython_step4</span><span class="p">(</span><span class="n">double</span> <span class="n">a</span><span class="p">,</span> <span class="n">double</span> <span class="n">b</span><span class="p">,</span> <span class="n">long</span> <span class="n">N</span><span class="p">):</span>   
</span><span class="hll">    <span class="n">cdef</span> <span class="n">double</span> <span class="n">s</span><span class="p">,</span> <span class="n">dx</span>
</span><span class="hll">    <span class="n">cdef</span> <span class="n">long</span> <span class="n">i</span>
</span>    
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">f_cython_step4</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span> <span class="o">*</span> <span class="n">dx</span>

<span class="hll"><span class="n">cpdef</span> <span class="n">double</span><span class="p">[:]</span> <span class="n">apply_integrate_f_cython_step4</span><span class="p">(</span>
</span>    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_a</span><span class="p">,</span>
    <span class="n">double</span><span class="p">[:]</span> <span class="n">col_b</span><span class="p">,</span>
    <span class="n">long</span><span class="p">[:]</span> <span class="n">col_N</span>
<span class="p">):</span>
<span class="hll">    <span class="n">cdef</span> <span class="n">long</span> <span class="n">n</span><span class="p">,</span><span class="n">i</span>
</span><span class="hll">    <span class="n">cdef</span> <span class="n">double</span><span class="p">[:]</span> <span class="n">res</span>
</span>    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_N</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">integrate_f_cython_step4</span><span class="p">(</span><span class="n">col_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">col_N</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div></div>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> apply_integrate_f_cython_step4(df[&#39;a&#39;].to_numpy(), df[&#39;b&#39;].to_numpy(), df[&#39;N&#39;].to_numpy())
<span class="c1"># 471 μs ± 7.38 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</span>
</pre></div>
</div>
<p>Now it is ~200 times faster than the baseline Python implementation, and all we have done is to add type declarations on the Python code!</p>
<figure class="align-left" id="id2">
<a class="reference internal image-reference" href="_images/cython_annotate_2.png"><img alt="_images/cython_annotate_2.png" src="_images/cython_annotate_2.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-text">We indeed see much less Python interaction in the code from step 1 to step 4.</span><a class="headerlink" href="#id2" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="other-useful-features">
<h3>Other useful features<a class="headerlink" href="#other-useful-features" title="Link to this heading">¶</a></h3>
<p>There are some useful (and possibly advanced) features which are not covered in this episode. Some of
these features are called <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/tutorial/pure.html#magic-attributes" title="(in Cython v3.2)"><span class="xref std std-ref">magic attributes</span></a>. Here are a few:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cython.cimports</span></code> package for importing and calling C libraries such as <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/tutorial/external.html#libc-math" title="(in Cython v3.2)"><span class="xref std std-ref">libc.math</span></a>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Differences between <code class="docutils literal notranslate"><span class="pre">import</span></code> (for Python) and <code class="docutils literal notranslate"><span class="pre">cimport</span></code> (for Cython) statements</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">import</span></code> gives access to Python libraries, functions or attributes</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cimport</span></code> gives access to C libraries, functions or attributes</p></li>
</ul>
<p>In case of Numpy it is common to use the following, and Cython will internally handle this ambiguity.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-UHVyZSBQeXRob24=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-4-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tab" tabindex="0">Pure Python</button><button aria-controls="panel-4-Q3l0aG9u" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-4-Q3l0aG9u" name="Q3l0aG9u" role="tab" tabindex="-1">Cython</button></div><div aria-labelledby="tab-4-UHVyZSBQeXRob24=" class="sphinx-tabs-panel group-tab" id="panel-4-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">cython.cimports.libc.stdlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">malloc</span><span class="p">,</span> <span class="n">free</span>  <span class="c1"># Allocate and free memory</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cython.cimports.libc</span><span class="w"> </span><span class="kn">import</span> <span class="n">math</span>  <span class="c1"># For math functions like sin, cos etc.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cython.cimports</span><span class="w"> </span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># access to NumPy C API</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-Q3l0aG9u" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-4-Q3l0aG9u" name="Q3l0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">libc.stdlib</span> <span class="n">cimport</span> <span class="n">malloc</span><span class="p">,</span> <span class="n">free</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">libc.libc</span> <span class="n">cimport</span> <span class="n">math</span>
<span class="n">cimport</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</pre></div>
</div>
</div></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cython.nogil</span></code>, which can act both as a decorator or context-manager, to manage the GIL (Global Interpreter Lock).
See <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/nogil.html#cython-and-gil" title="(in Cython v3.2)"><span>Cython and the GIL</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&#64;cython.boundscheck(False)</span></code> and <code class="docutils literal notranslate"><span class="pre">&#64;cython.wraparound(False)</span></code> decorators to tune indexing of Numpy array.
See <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/numpy_tutorial.html#numpy-tutorial" title="(in Cython v3.2)"><span>Cython for NumPy users</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&#64;cython.cclass</span></code> to declare <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/userguide/extension_types.html#extension-types" title="(in Cython v3.2)"><span>Extension Types</span></a> which behave similar to Python classes.</p></li>
</ul>
<p>In addition to the above Cython can also,</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cython.readthedocs.io/en/stable/src/tutorial/pure.html#augmenting-pxd" title="(in Cython v3.2)"><span class="xref std std-ref">augment with .pxd files</span></a> where the Python code is kept as it is and the <code class="docutils literal notranslate"><span class="pre">.pxd</span></code> file
describes the type annotation. In this form <code class="docutils literal notranslate"><span class="pre">.pxd</span></code> is very similar in function to a C/C++ header file
or <code class="docutils literal notranslate"><span class="pre">.pyi</span></code> Python type annnotation file,</p></li>
<li><p>create parallel code using <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/tutorial/parallelization.html#parallel-block" title="(in Cython v3.2)"><span>parallel blocks</span></a> and <code class="docutils literal notranslate"><span class="pre">prange</span></code> iterator for element-wise parallel operation or reductions
based on OpenMP threads (see <a class="reference external" href="https://cython.readthedocs.io/en/stable/src/tutorial/parallelization.html#parallel-tutorial" title="(in Cython v3.2)"><span>Writing parallel code with Cython</span></a>).</p></li>
</ul>
<div class="admonition-demo demo admonition" id="demo-1">
<p class="admonition-title">Demo</p>
<p>Here is a code which showcases most of the features above, except the <code class="docutils literal notranslate"><span class="pre">&#64;cython.cclass</span></code> feature and the use of <code class="docutils literal notranslate"><span class="pre">.pxd</span></code> files.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-5-UHVyZSBQeXRob24=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-5-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tab" tabindex="0">Pure Python</button><button aria-controls="panel-5-Q3l0aG9u" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-Q3l0aG9u" name="Q3l0aG9u" role="tab" tabindex="-1">Cython</button><button aria-controls="panel-5-TnVtcHk=" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-TnVtcHk=" name="TnVtcHk=" role="tab" tabindex="-1">Numpy</button><button aria-controls="panel-5-TmFpdmUgUHl0aG9uIGltcGxlbWVudGF0aW9u" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-5-TmFpdmUgUHl0aG9uIGltcGxlbWVudGF0aW9u" name="TmFpdmUgUHl0aG9uIGltcGxlbWVudGF0aW9u" role="tab" tabindex="-1">Naive Python implementation</button></div><div aria-labelledby="tab-5-UHVyZSBQeXRob24=" class="sphinx-tabs-panel group-tab" id="panel-5-UHVyZSBQeXRob24=" name="UHVyZSBQeXRob24=" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cython</span>
<span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">cython.parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">parallel</span><span class="p">,</span> <span class="n">prange</span>
</span><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">cython.cimports.libc.math</span><span class="w"> </span><span class="kn">import</span> <span class="n">sqrt</span>
</span>
<span class="hll"><span class="nd">@cython</span><span class="o">.</span><span class="n">boundscheck</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</span><span class="hll"><span class="nd">@cython</span><span class="o">.</span><span class="n">wraparound</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</span><span class="k">def</span><span class="w"> </span><span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span><span class="p">[:]):</span>
<span class="w">   </span><span class="sd">&quot;&quot;&quot;Normalize a 1D array by dividing all its elements using its root-mean-square (RMS) value.&quot;&quot;&quot;</span>
   <span class="n">i</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">Py_ssize_t</span>
   <span class="n">total</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span> <span class="o">=</span> <span class="mi">0</span>
   <span class="n">norm</span><span class="p">:</span> <span class="n">cython</span><span class="o">.</span><span class="n">double</span>
<span class="hll">   <span class="k">with</span> <span class="n">cython</span><span class="o">.</span><span class="n">nogil</span><span class="p">,</span> <span class="n">parallel</span><span class="p">():</span>
</span><span class="hll">      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span>            <span class="n">total</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="n">norm</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="n">norm</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-Q3l0aG9u" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-Q3l0aG9u" name="Q3l0aG9u" role="tabpanel" tabindex="0"><div class="highlight-cython notranslate"><div class="highlight"><pre><span></span><span class="k">cimport</span><span class="w"> </span><span class="nn">cython</span>
<span class="hll"><span class="k">from</span><span class="w"> </span><span class="nn">cython.parallel</span><span class="w"> </span><span class="k">cimport</span> <span class="n">parallel</span><span class="p">,</span> <span class="n">prange</span>
</span><span class="hll"><span class="k">from</span><span class="w"> </span><span class="nn">libc.math</span><span class="w"> </span><span class="k">cimport</span> <span class="n">sqrt</span>
</span>
<span class="hll"><span class="nd">@cython</span><span class="o">.</span><span class="n">boundscheck</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</span><span class="hll"><span class="nd">@cython</span><span class="o">.</span><span class="n">wraparound</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
</span><span class="k">def</span><span class="w"> </span><span class="nf">normalize</span><span class="p">(</span><span class="n">double</span><span class="p">[:]</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Normalize a 1D array by dividing all its elements using its root-mean-square (RMS) value.&quot;&quot;&quot;</span>
    <span class="k">cdef</span><span class="w"> </span><span class="kt">Py_ssize_t</span> <span class="nf">i</span>
    <span class="k">cdef</span><span class="w"> </span><span class="kt">double</span> <span class="nf">total</span><span class="w"> </span><span class="o">=</span> <span class="mf">0</span>
    <span class="k">cdef</span><span class="w"> </span><span class="kt">double</span> <span class="nf">norm</span>
<span class="hll">    <span class="k">with</span> <span class="k">nogil</span><span class="p">,</span> <span class="n">parallel</span><span class="p">():</span>
</span><span class="hll">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mf">0</span><span class="p">]):</span>
</span>            <span class="n">total</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mf">0</span><span class="p">]):</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="n">norm</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-TnVtcHk=" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-TnVtcHk=" name="TnVtcHk=" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">normalize_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">total</span> <span class="o">**</span> <span class="mf">0.5</span>

    <span class="n">x</span><span class="p">[:]</span> <span class="o">/=</span> <span class="n">norm</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-5-TmFpdmUgUHl0aG9uIGltcGxlbWVudGF0aW9u" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-5-TmFpdmUgUHl0aG9uIGltcGxlbWVudGF0aW9u" name="TmFpdmUgUHl0aG9uIGltcGxlbWVudGF0aW9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">sqrt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">normalize_naive</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">norm</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="n">norm</span>
</pre></div>
</div>
</div></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you compare performance of the the Cython code versus the Numpy code, you might observe that it is either on-par, or slightly worse than Numpy.
This is because Numpy vectorized operations also makes use of OpenMP parallelism and is heavily optimized. Nevertheless, it is orders of magnitude
better than a naive implementation.</p>
</div>
</div>
</section>
<section id="conclusions">
<h3>Conclusions<a class="headerlink" href="#conclusions" title="Link to this heading">¶</a></h3>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Cython is a versatile, general purpose compiler for Python code</p></li>
<li><p>Cython is a great way to write high-performance code in Python where algorithms are not available in scientific libraries like Numpy and Scipy and
require custom implementation</p></li>
</ul>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>In order to make Cython code reusable often some packaging is necessary. The compilation to binary extension can either happen during the packaging itself, or
during installation of a Python package. To learn more about how to package such extensions, read the following guides:</p>
<ul class="simple">
<li><p><em>pyOpenSci Python packaging guide</em>’s page on <a class="reference external" href="https://www.pyopensci.org/python-package-guide/package-structure-code/python-package-build-tools.html">build tools</a></p></li>
<li><p><em>Python packaging user guide</em>’s page on <a class="reference external" href="https://packaging.python.org/en/latest/guides/packaging-binary-extensions/">packaging binary extensions</a></p></li>
</ul>
</div>
</section>
</section>
<span id="document-cupy"></span><section id="cupy">
<h2>CuPy<a class="headerlink" href="#cupy" title="Link to this heading">¶</a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>How could I make my Python code to run on a GPU?</p></li>
<li><p>How do I copy data to the GPU memory?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand the basics of the library CuPy and its functionalities</p></li>
<li><p>Analyze and detect whether a variable is stored in the CPU or GPU memory</p></li>
<li><p>Execute a data-copy operation from host to device memory and vice versa</p></li>
<li><p>Re-write a simple NumPy/SciPy
function, to program the CuPy equivalent which runs on the GPUs</p></li>
</ul>
<!-- - Be able to profile a simple function
  and estimate the speed-up by using GPU -->
</div>
<section id="introduction-to-cupy">
<h3>Introduction to CuPy<a class="headerlink" href="#introduction-to-cupy" title="Link to this heading">¶</a></h3>
<p>Another excellent tool for writing Python code to run on GPUs is CuPy.
CuPy implements most of the NumPy/SciPy operations
and acts as a drop-in replacement to run existing
code on both NVIDIA CUDA or AMD ROCm platforms.
By design, the CuPy interface is as close as possible to NumPy/SciPy,
making code porting much easier.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A common misconception is that CuPy is an official NVIDIA project.
It is rather a community driven project. Originally it was developed
to support a deep-learning framework called Chainer (now deprecated),
wherein it only supported CUDA as a target. Nowadays CuPy has
great support for both NVIDIA CUDA or AMD ROCm platforms.</p>
</div>
</section>
<section id="basics-of-cupy">
<h3>Basics of CuPy<a class="headerlink" href="#basics-of-cupy" title="Link to this heading">¶</a></h3>
<p>CuPy’s syntax here is identical to that of NumPy. A list of
NumPy/SciPy APIs and its corresponding CuPy implementations
is summarised here:</p>
<p><a class="reference external" href="https://docs.cupy.dev/en/stable/reference/comparison.html#comparison-table">Complete Comparison of NumPy and SciPy to CuPy functions</a>.</p>
<p>In short, CuPy provides N-dimensional array (ndarray),
sparse matrices, and the associated routines for GPU devices,
most having the same API as NumPy/SciPy.</p>
<p>Let us take a look at the following code snippet which calculates the L2-norm of an array.
Note how simple it is to run on a GPU device using CuPy, i.e. essentially by changing np to cp.</p>
<table>
<tr>
<th>NumPy</th>
<th>CuPy</th>
</tr>
<tr>
<td>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">x_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">l2_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_cpu</span><span class="p">)</span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="n">x_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="p">,</span><span class="mi">2</span> <span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">l2_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">)</span>
</pre></div>
</div>
</td>
</tr>
</table>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Do not change the import line
in the code to something like</p>
<p><code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">cupy</span> <span class="pre">as</span> <span class="pre">np</span></code></p>
<p>which can cause problems if you need to use
NumPy code and not CuPy code.</p>
</div>
<section id="conversion-to-from-numpy-arrays">
<h4>Conversion to/from NumPy arrays<a class="headerlink" href="#conversion-to-from-numpy-arrays" title="Link to this heading">¶</a></h4>
<p>Although <code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code> is the CuPy counterpart of NumPy <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>,
the main difference is that <code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code> resides on the <code class="docutils literal notranslate"><span class="pre">current</span> <span class="pre">device</span></code>,
and they are not implicitly convertible to each other.
When you need to manipulate CPU and GPU arrays, an explicit data transfer
may be required to move them to the same location – either CPU or GPU.
For this purpose, CuPy implements the following methods:</p>
<ul class="simple">
<li><p>To convert <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> to <code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code>, use <code class="docutils literal notranslate"><span class="pre">cupy.array()</span></code> or <code class="docutils literal notranslate"><span class="pre">cupy.asarray()</span></code></p></li>
<li><p>To convert <code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code> to <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>, use <code class="docutils literal notranslate"><span class="pre">cupy.asnumpy()</span></code> or <code class="docutils literal notranslate"><span class="pre">cupy.ndarray.get()</span></code></p></li>
</ul>
<p>These methods can accept arbitrary input, meaning that they can be applied to any data
that is located on either the host or device.</p>
<p>Here is an example that demonstrates the use of both methods:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="c1"># allocating array x on cpu</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span> <span class="c1"># allocating array y on cpu</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_cpu</span> <span class="o">+</span> <span class="n">y_cpu</span> <span class="c1"># add x and y</span>
<span class="go">array([5, 7, 9])</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_cpu</span><span class="p">)</span> <span class="c1"># move x to gpu</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_gpu</span> <span class="o">+</span> <span class="n">y_cpu</span> <span class="c1"># now it should fail</span>
<span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;&lt;stdin&gt;&quot;</span>, line <span class="m">1</span>, in <span class="n">&lt;module&gt;</span>
  File <span class="nb">&quot;cupy/_core/core.pyx&quot;</span>, line <span class="m">1375</span>, in <span class="n">cupy._core.core._ndarray_base.__add__</span>
  File <span class="nb">&quot;cupy/_core/core.pyx&quot;</span>, line <span class="m">1799</span>, in <span class="n">cupy._core.core._ndarray_base.__array_ufunc__</span>
  File <span class="nb">&quot;cupy/_core/_kernel.pyx&quot;</span>, line <span class="m">1285</span>, in <span class="n">cupy._core._kernel.ufunc.__call__</span>
  File <span class="nb">&quot;cupy/_core/_kernel.pyx&quot;</span>, line <span class="m">159</span>, in <span class="n">cupy._core._kernel._preprocess_args</span>
  File <span class="nb">&quot;cupy/_core/_kernel.pyx&quot;</span>, line <span class="m">145</span>, in <span class="n">cupy._core._kernel._preprocess_arg</span>
<span class="gr">TypeError</span>: <span class="n">Unsupported type &lt;class &#39;numpy.ndarray&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">)</span> <span class="o">+</span> <span class="n">y_cpu</span>
<span class="go">array([5, 7, 9])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">)</span> <span class="o">+</span> <span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">y_cpu</span><span class="p">)</span>
<span class="go">array([5, 7, 9])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_gpu</span> <span class="o">+</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_cpu</span><span class="p">)</span>
<span class="go">array([5, 7, 9])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_gpu</span><span class="p">)</span> <span class="o">+</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_cpu</span><span class="p">)</span>
<span class="go">array([5, 7, 9])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Converting between <code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code> and <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> incurs data transfer
between the host (CPU) device and the GPU device,
which is costly in terms of performance.</p>
</div>
</section>
<section id="current-device">
<h4>Current Device<a class="headerlink" href="#current-device" title="Link to this heading">¶</a></h4>
<p>CuPy introduces the concept of a <code class="docutils literal notranslate"><span class="pre">current</span> <span class="pre">device</span></code>,
which represents the default GPU device on which
the allocation, manipulation, calculation, etc.,
of arrays take place. <code class="docutils literal notranslate"><span class="pre">cupy.ndarray.device</span></code> attribute
can be used to determine the device allocated to a CuPy array.
By default, ID of the current device is 0.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_gpu</span><span class="o">.</span><span class="n">device</span>
<span class="go">&lt;CUDA Device 0&gt;</span>
</pre></div>
</div>
<p>To obtain the total number of accessible devices,
one can utilize the <code class="docutils literal notranslate"><span class="pre">getDeviceCount</span></code> function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">getDeviceCount</span><span class="p">()</span>
<span class="go">1</span>
</pre></div>
</div>
<p>To switch to another GPU device, use the <code class="docutils literal notranslate"><span class="pre">Device</span></code> context manager.
For example, the following code snippet creates an array on GPU 1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">cp</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Device</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
<span class="go">       x_gpu1 = cp.array([1, 2, 3, 4, 5])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_gpu1 is on device:&quot;</span> <span class="n">x_gpu1</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Sometimes it is more convenient to set the device globally:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">setDevice</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>All CuPy operations (except for multi-GPU features
and device-to-device copy) are performed
on the currently active device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The device will be called &lt;CUDA Device 0&gt; even if you are on AMD GPUs.</p>
<p>In general, CuPy functions expect that
the data array is on the current device.
Passing an array stored on a non-current
device may work depending on the hardware configuration
but is generally discouraged as it may not be performant.</p>
</div>
</section>
<section id="exercises-matrix-multiplication">
<h4>Exercises: Matrix Multiplication<a class="headerlink" href="#exercises-matrix-multiplication" title="Link to this heading">¶</a></h4>
<div class="admonition-exercise-matrix-multiplication exercise important admonition" id="exercise-0">
<p class="admonition-title">Exercise : Matrix Multiplication</p>
<p>The first example is a simple matrix multiplication in single precision (float32).
The arrays are created with random values in the range of -1.0 to 1.0.
Convert the NumPy code to run on GPU using CuPy.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
 
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
 
<span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice in this snippet of code that the variable C remains on the GPU.
You have to copy it back to the CPU explicitly if needed.
Otherwise all the data on the GPU is wiped once the code ends.</p>
</div>
</section>
<section id="exercises-moving-data-from-gpu-to-cpu">
<h4>Exercises: moving data from GPU to CPU<a class="headerlink" href="#exercises-moving-data-from-gpu-to-cpu" title="Link to this heading">¶</a></h4>
<div class="admonition-exercise-moving-data-from-gpu-to-cpu exercise important admonition" id="exercise-1">
<p class="admonition-title">Exercise : moving data from GPU to CPU</p>
<p>The code snippet simply computes a singular value decomposition (SVD)
of a matrix. In this case, the matrix is a
single-precision 64x64 matrix of random values. First re-write the code
using CuPy for GPU enabling. Second, adding a few lines to
copy variable u back to CPU and print objects’ type using <code class="docutils literal notranslate"><span class="pre">type()</span></code> function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
 
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
 
<span class="n">A</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">u_gpu</span><span class="p">,</span> <span class="n">s_gpu</span><span class="p">,</span> <span class="n">v_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;type(u_gpu) = &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">u_gpu</span><span class="p">))</span>
<span class="n">u_cpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(</span><span class="n">u_gpu</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;type(u_cpu) = &quot;</span><span class="p">,</span><span class="nb">type</span><span class="p">(</span><span class="n">u_cpu</span><span class="p">))</span>
</pre></div>
</div>
</div>
</section>
<section id="exercises-cupy-vs-numpy-scipy">
<h4>Exercises: CuPy vs Numpy/SciPy<a class="headerlink" href="#exercises-cupy-vs-numpy-scipy" title="Link to this heading">¶</a></h4>
<div class="admonition-cupy-vs-numpy-scipy exercise important admonition" id="exercise-2">
<p class="admonition-title">CuPy vs Numpy/SciPy</p>
<p>Although the CuPy team focuses on providing a complete
NumPy/SciPy API coverage to become a full drop-in replacement,
some important differences between CuPy and NumPy should be noted,
one should keep these differences in mind when porting NumPy code to CuPy.</p>
<!--
- Some casting behaviors from floating point to integer
are not defined in the C++ specification. The casting
from a negative floating point to an unsigned integer
and from infinity to an integer are examples.
- CuPy random methods support the dtype argument.
- Out-of-bounds indices and duplicate values in indices are handled differently.
- Reduction methods return zero-dimension arrays.
-->
<p>Here are various examples illustrating the differences</p>
</div>
<div class="admonition-when-cupy-is-different-from-numpy-scipy solution important dropdown admonition" id="solution-2">
<p class="admonition-title">When CuPy is different from NumPy/SciPy</p>
<p class="rubric" id="cast-behavior-from-float-to-integer">Cast behavior from float to integer</p>
<p>Some casting behaviors from float to integer
are not defined in C++ specification.
The casting from a negative float to
unsigned integer and infinity to integer
is one of such examples. The behavior of NumPy
depends on your CPU architecture.
This is the result on an Intel CPU:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">)</span>
<span class="go">array([4294967295], dtype=uint32)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">)</span>
<span class="go">array([0], dtype=uint32)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">array([-2147483648], dtype=int32)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">array([2147483647], dtype=int32)</span>
</pre></div>
</div>
<p class="rubric" id="random-methods-support-dtype-argument">Random methods support dtype argument</p>
<p>NumPy’s random value generator does not support
a dtype argument and instead always returns
a float64 value. While in CuPy, both
float32 and float64 are supported because of cuRAND.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;&lt;stdin&gt;&quot;</span>, line <span class="m">1</span>, in <span class="n">&lt;module&gt;</span>
<span class="gr">TypeError</span>: <span class="n">randn() got an unexpected keyword argument &#39;dtype&#39;</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  
<span class="go">array(1.3591791, dtype=float32)</span>
</pre></div>
</div>
<p class="rubric" id="out-of-bounds-indices">Out-of-bounds indices</p>
<p>CuPy handles out-of-bounds indices differently
by default from NumPy when using integer array indexing.
NumPy handles them by raising an error, but CuPy wraps around them.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;&lt;stdin&gt;&quot;</span>, line <span class="m">1</span>, in <span class="n">&lt;module&gt;</span>
<span class="gr">IndexError</span>: <span class="n">index 3 is out of bounds for axis 0 with size 3</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
<span class="go">array([1, 0])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">array([10, 10,  2])</span>
</pre></div>
</div>
<p class="rubric" id="duplicate-values-in-indices">Duplicate values in indices</p>
<p>CuPy’s <code class="docutils literal notranslate"><span class="pre">__setitem__</span></code> behaves differently from NumPy
when integer arrays reference the same location multiple times.
NumPy stores the value corresponding to the last element
among elements referencing duplicate locations.
In CuPy, the value that is actually stored is undefined.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([9998., 9999.])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>  
<span class="go">array([4592., 4593.])</span>
</pre></div>
</div>
<p class="rubric" id="zero-dimensional-array">Zero-dimensional array</p>
<p class="rubric" id="reduction-methods">Reduction methods</p>
<p>NumPy’s reduction functions (e.g. <code class="docutils literal notranslate"><span class="pre">numpy.sum()</span></code>) return
scalar values (e.g. <code class="docutils literal notranslate"><span class="pre">numpy.float32</span></code>). However
CuPy counterparts return zero-dimensional <code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code>.
That is because CuPy scalar values (e.g. <code class="docutils literal notranslate"><span class="pre">cupy.float32</span></code>)
are aliases of NumPy scalar values and are allocated
in CPU memory. If these types were returned, it would be
required to synchronize between GPU and CPU. If you want to
use scalar values, cast the returned arrays explicitly.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)))</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span>
<span class="go">True</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)))</span> <span class="o">==</span> <span class="n">cp</span><span class="o">.</span><span class="n">ndarray</span>
<span class="go">True</span>
</pre></div>
</div>
<p class="rubric" id="type-promotion">Type promotion</p>
<p>CuPy automatically promotes dtypes of <code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code>
in a function with two or more operands, the result dtype
is determined by the dtypes of the inputs. This is different
from NumPy’s rule on type promotion, when operands contain
zero-dimensional arrays. Zero-dimensional <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>
are treated as if they were scalar values if they appear
in operands of NumPy’s function. This may affect the dtype
of its output, depending on the values of the “scalar” inputs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float32&#39;)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="o">*</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float64&#39;)</span>
</pre></div>
</div>
<p class="rubric" id="matrix-type-numpy-matrix">Matrix type (<code class="docutils literal notranslate"><span class="pre">numpy.matrix</span></code>)</p>
<p>SciPy returns <code class="docutils literal notranslate"><span class="pre">numpy.matrix</span></code> (a subclass of <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>)
when dense matrices are computed from sparse matrices
(e.g., coo_matrix + ndarray). However, CuPy returns
<code class="docutils literal notranslate"><span class="pre">cupy.ndarray</span></code> for such operations.</p>
<p>There is no plan to provide <code class="docutils literal notranslate"><span class="pre">numpy.matrix</span></code> equivalent in CuPy.
This is because the use of <code class="docutils literal notranslate"><span class="pre">numpy.matrix</span></code> is no longer
recommended since NumPy 1.15.</p>
<p class="rubric" id="data-types">Data types</p>
<p>Data type of CuPy arrays cannot be non-numeric like strings or objects.</p>
<p class="rubric" id="universal-functions-only-work-with-cupy-array-or-scalar">Universal Functions only work with CuPy array or scalar</p>
<p>Unlike NumPy, Universal Functions in CuPy only work with
CuPy array or scalar. They do not accept other objects
(e.g., lists or <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)],</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[ 0,  1,  4,  9, 16]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">cp</span><span class="o">.</span><span class="n">power</span><span class="p">([</span><span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)],</span> <span class="mi">2</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
  File <span class="nb">&quot;&lt;stdin&gt;&quot;</span>, line <span class="m">1</span>, in <span class="n">&lt;module&gt;</span>
  File <span class="nb">&quot;cupy/_core/_kernel.pyx&quot;</span>, line <span class="m">1285</span>, in <span class="n">cupy._core._kernel.ufunc.__call__</span>
  File <span class="nb">&quot;cupy/_core/_kernel.pyx&quot;</span>, line <span class="m">159</span>, in <span class="n">cupy._core._kernel._preprocess_args</span>
  File <span class="nb">&quot;cupy/_core/_kernel.pyx&quot;</span>, line <span class="m">145</span>, in <span class="n">cupy._core._kernel._preprocess_arg</span>
<span class="gr">TypeError</span>: <span class="n">Unsupported type &lt;class &#39;list&#39;&gt;</span>
</pre></div>
</div>
<p class="rubric" id="random-seed-arrays-are-hashed-to-scalars">Random seed arrays are hashed to scalars</p>
<p>Like NumPy, CuPy’s RandomState objects accept seeds
either as numbers or as full NumPy arrays.</p>
<p>However, unlike NumPy, array seeds will be hashed down
to a single number of 64 bits. In contrast, NumPy often
converts the seeds into a larger state space of 128 bits.
Therefore, CuPy’s implementation may not communicate as
much entropy to the underlying random number generator.</p>
<!--
```
>>> seed = np.array([1, 2, 3, 4, 5])
>>> rs = cp.random.RandomState(seed=seed)
```
-->
<p class="rubric" id="nan-not-a-number-handling">NaN (not-a-number) handling</p>
<p>Prior to CuPy v11, CuPy’s reduction functions (e.g., <code class="docutils literal notranslate"><span class="pre">cupy.sum()</span></code>)
handle NaNs in complex numbers differently from NumPy’s counterparts:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span> <span class="o">+</span> <span class="mf">3.7</span><span class="n">j</span><span class="p">,</span> <span class="nb">complex</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">),</span> <span class="nb">complex</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.9</span><span class="p">),</span> <span class="nb">complex</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">[(0.5+3.7j), (0.7+nanj), (nan-3.9j), (nan+nanj)]</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a_np</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">a_np</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="go">(0.7+nanj) (0.7+nanj)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_cp</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a_np</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a_cp</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">a_cp</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="go">(nan-3.9j) (nan-3.9j)</span>
</pre></div>
</div>
<p>The reason is that internally the reduction is performed
in a strided fashion, thus it does not ensure a
proper comparison order and cannot follow NumPy’s rule
to always propagate the first-encountered NaN.
This difference does not apply when CUB library is enabled
which is the default for CuPy v11 and later.</p>
<p class="rubric" id="contiguity-strides">Contiguity / Strides</p>
<p>To provide the best performance, the contiguity of
a resulting ndarray is not guaranteed to match with
that of NumPy’s output.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([[1, 2],</span>
<span class="go">       [3, 4]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">((</span><span class="n">a</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">f_contiguous</span><span class="p">)</span>
<span class="go">True</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([[1, 2],</span>
<span class="go">       [3, 4]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">((</span><span class="n">a</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">f_contiguous</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="interoperability">
<h3>Interoperability<a class="headerlink" href="#interoperability" title="Link to this heading">¶</a></h3>
<p>CuPy implements standard APIs for data exchange and interoperability,
which means it can be used in conjunction with
any other libraries supporting the standard. For example,
NumPy, Numba, PyTorch, TensorFlow, MPI4Py among others
can be directly operated on CuPy arrays.</p>
<section id="numpy">
<h4>NumPy<a class="headerlink" href="#numpy" title="Link to this heading">¶</a></h4>
<p>CuPy implements <code class="docutils literal notranslate"><span class="pre">__array_ufunc__</span></code> interface
<a class="reference external" href="https://numpy.org/neps/nep-0013-ufunc-overrides.html">(see NEP 13)</a>,
<code class="docutils literal notranslate"><span class="pre">__array_function__</span></code> interface
<a class="reference external" href="https://numpy.org/neps/nep-0018-array-function-protocol.html">(see NEP 18)</a>,
and other <a class="reference external" href="https://data-apis.org/array-api/latest">Python Array API Standard</a>.</p>
<p>Note that the return type of these operations is still consistent with the initial type.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dev_arr</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dev_arr</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>
<span class="go">&lt;class &#39;cupy.ndarray&#39;&gt;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">__array_ufunc__</span></code> feature requires NumPy 1.13 or later</p>
<p><code class="docutils literal notranslate"><span class="pre">__array_function__</span></code> feature requires NumPy 1.16 or later.
As of NumPy 1.17, <code class="docutils literal notranslate"><span class="pre">__array_function__</span></code> is enabled by default</p>
<p>NEP 13 — A mechanism for overriding Ufuncs</p>
<p>NEP 18 — A dispatch mechanism for NumPy’s high level array functions</p>
</div>
</section>
<section id="numba">
<h4>Numba<a class="headerlink" href="#numba" title="Link to this heading">¶</a></h4>
<p>CuPy implements <code class="docutils literal notranslate"><span class="pre">__cuda_array_interface__</span></code>
which is compatible with Numba v0.39.0 or later
(see <a class="reference external" href="https://numba.readthedocs.io/en/stable/cuda/cuda_array_interface.html">CUDA Array Interface</a>
for details). It means one can pass CuPy arrays to kernels JITed with Numba.</p>
<p>################### FIXME: crashes when launching</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numba</span><span class="w"> </span><span class="kn">import</span> <span class="n">cuda</span>

<span class="nd">@cuda</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">gridsize</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stride</span><span class="p">):</span>
                <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">2</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># =&gt; [0 0 0 0 0 0 0 0 0 0]</span>

<span class="n">add</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">](</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># =&gt; [ 0  3  6  9 12 15 18 21 24 27]</span>
</pre></div>
</div>
<p>In addition, <code class="docutils literal notranslate"><span class="pre">cupy.asarray()</span></code> supports zero-copy conversion from Numba CUDA array to CuPy array.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numba</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">&lt;class &#39;numpy.ndarray&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_numba</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">x_numba</span><span class="p">)</span>
<span class="go">&lt;class &#39;numba.cuda.cudadrv.devicearray.DeviceNDArray&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_cupy</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_numba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">x_cupy</span><span class="p">)</span>
<span class="go">&lt;class &#39;cupy.ndarray&#39;&gt;</span>
</pre></div>
</div>
</section>
<section id="cpu-gpu-agnostic-code">
<h4>CPU/GPU agnostic code<a class="headerlink" href="#cpu-gpu-agnostic-code" title="Link to this heading">¶</a></h4>
<p>Once beginning porting code to the GPU, one has to
consider how to handle creating data on either the CPU or GPU.
CuPy’s compatibility with NumPy/SciPy makes it possible to write CPU/GPU agnostic code.
For this purpose, CuPy implements the <code class="docutils literal notranslate"><span class="pre">cupy.get_array_module()</span></code> function that
returns a reference to cupy if any of its arguments resides on a GPU and numpy otherwise.</p>
<p>Here is an example of a CPU/GPU agnostic function</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># define a simple function: f(x)=x+1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">addone</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">xp</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">get_array_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># Returns cupy if any array is on the GPU, otherwise numpy.  &#39;xp&#39; is a standard usage in the community</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Using:&quot;</span><span class="p">,</span> <span class="n">xp</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">x</span><span class="o">+</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create an array and copy it to GPU</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_cpu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a_gpu</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a_cpu</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># GPU/CPU agnostic code also works with CuPy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">addone</span><span class="p">(</span><span class="n">a_cpu</span><span class="p">))</span>
<span class="go">Using: numpy</span>
<span class="go">[ 1  3  5  7  9 11 13 15 17 19]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">addone</span><span class="p">(</span><span class="n">a_gpu</span><span class="p">))</span>
<span class="go">Using: cupy</span>
<span class="go">[ 1  3  5  7  9 11 13 15 17 19]</span>
</pre></div>
</div>
</section>
</section>
<section id="user-defined-kernels">
<h3>User-Defined Kernels<a class="headerlink" href="#user-defined-kernels" title="Link to this heading">¶</a></h3>
<p>Sometimes you need a specific GPU function or routine
that is not provided by an existing library or tool.
In these situation, you need to write a “custom kernel”,
i.e. a user-defined GPU kernel. Custom kernels written
with CuPy only require a small snippet of code
and CuPy automatically wraps and compiles it.
Compiled binaries are then cached and reused in subsequent runs.</p>
<p>CuPy provides three templates of user-defined kernels:</p>
<ul class="simple">
<li><p>cupy.ElementwiseKernel: User-defined elementwise kernel</p></li>
<li><p>cupy.ReductionKernel: User-defined reduction kernel</p></li>
<li><p>cupy.RawKernel: User-defined CUDA/HIP kernel</p></li>
</ul>
<section id="elementwisekernel">
<h4>ElementwiseKernel<a class="headerlink" href="#elementwisekernel" title="Link to this heading">¶</a></h4>
<p>The element-wise kernel focuses on kernels that operate on an element-wise basis.
An element-wise kernel has four components:</p>
<ul class="simple">
<li><p>input argument list</p></li>
<li><p>output argument list</p></li>
<li><p>function code</p></li>
<li><p>kernel name</p></li>
</ul>
<p>The argument lists consist of comma-separated argument definitions.
Each argument definition consists of a type specifier and an argument name.
Names of NumPy data types can be used as type specifiers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">my_kernel</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">ElementwiseKernel</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;float32 x, float32 y&#39;</span><span class="p">,</span>  <span class="c1"># input arg list</span>
<span class="gp">... </span>   <span class="s1">&#39;float32 z&#39;</span><span class="p">,</span>             <span class="c1"># output arg list</span>
<span class="gp">... </span>   <span class="s1">&#39;z = (x - y) * (x - y)&#39;</span><span class="p">,</span> <span class="c1"># function</span>
<span class="gp">... </span>   <span class="s1">&#39;my_kernel&#39;</span><span class="p">)</span>             <span class="c1"># kernel name</span>
</pre></div>
</div>
<p>In the first line, the object instantiation is named <code class="docutils literal notranslate"><span class="pre">my_kernel</span></code>.
The next line has the variables to be used as input (x and y) and output (z).
These variables can be typed with NumPy data types, as shown.
The function code then follows. The last line states the kernel name,
which is <code class="docutils literal notranslate"><span class="pre">my_kernel</span></code>, in this case.</p>
<p>The above kernel can be called on either scalars or arrays
since the ElementwiseKernel class does the indexing with broadcasting automatically:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># user-defined kernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_kernel</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">ElementwiseKernel</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;float32 x, float32 y&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;float32 z&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;z = (x - y) * (x - y)&#39;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s1">&#39;my_kernel&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># allocating arrays x and y</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># launch the kernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="go">array([[ 0.,  0.,  0.,  0.,  0.],</span>
<span class="go">       [25., 25., 25., 25., 25.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="go">array([[25., 16.,  9.,  4.,  1.],</span>
<span class="go">       [ 0.,  1.,  4.,  9., 16.]], dtype=float32)</span>
</pre></div>
</div>
<p>Sometimes it would be nice to create a generic kernel that can handle multiple data types.
CuPy allows this with the use of a type placeholder.
The above <code class="docutils literal notranslate"><span class="pre">my_kernel</span></code> can be made type-generic as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">my_kernel_generic</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">ElementwiseKernel</span><span class="p">(</span>
   <span class="s1">&#39;T x, T y&#39;</span><span class="p">,</span>
   <span class="s1">&#39;T z&#39;</span><span class="p">,</span>
   <span class="s1">&#39;z = (x - y) * (x - y)&#39;</span><span class="p">,</span>
   <span class="s1">&#39;my_kernel_generic&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If a type specifier is one character, T in this case,
it is treated as a <strong>type placeholder</strong>. Same character
in the kernel definition indicates the same type.
More than one type placeholder can be used in a kernel definition.
The actual type of these placeholders is determined
by the actual argument type. The ElementwiseKernel class
first checks the output arguments and then the input arguments
to determine the actual type. If no output arguments are given
on the kernel invocation, only the input arguments
are used to determine the type.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">my_kernel_generic2</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">ElementwiseKernel</span><span class="p">(</span>
    <span class="s1">&#39;X x, Y y&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Z z&#39;</span><span class="p">,</span>
    <span class="s1">&#39;z = (x - y) * (x - y)&#39;</span><span class="p">,</span>
    <span class="s1">&#39;my_kernel_generic2&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This above kernel, i.e. <code class="docutils literal notranslate"><span class="pre">my_kernel_generic2</span></code>,
requires the output argument to be explicitly specified,
because the type Z cannot be automatically determined from
the input arguments X and Y.</p>
</div>
</section>
<section id="reductionkernel">
<h4>ReductionKernel<a class="headerlink" href="#reductionkernel" title="Link to this heading">¶</a></h4>
<p>The second type of CuPy custom kernel is the reduction kernel,
which is focused on kernels of the Map-Reduce type.
The ReductionKernel class has four extra parts:</p>
<ul class="simple">
<li><p>Identity value: Initial value of the reduction</p></li>
<li><p>Mapping expression: Pre-processes each element to be reduced</p></li>
<li><p>Reduction expression: An operator to reduce the multiple mapped values.
Two special variables, a and b, are used for this operand</p></li>
<li><p>Post-mapping expression: Transforms the resulting reduced values.
The special variable a is used as input. The output should be written to the output variable</p></li>
</ul>
<p>Here is an example to compute L2 norm along specified axies:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># user-defined kernel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l2norm_kernel</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">ReductionKernel</span><span class="p">(</span>
<span class="go">    &#39;T x&#39;,  # input arg list</span>
<span class="go">    &#39;T y&#39;,  # output arg list</span>
<span class="go">    &#39;x * x&#39;,  # mapping</span>
<span class="go">    &#39;a + b&#39;,  # reduction</span>
<span class="go">    &#39;y = sqrt(a)&#39;,  # post-reduction mapping function</span>
<span class="go">    &#39;0&#39;,  # identity value</span>
<span class="go">    &#39;l2norm&#39;  # kernel name</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># allocating array</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">array([[0., 1., 2., 3., 4.],</span>
<span class="go">       [5., 6., 7., 8., 9.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># kernel launch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l2norm_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([ 5.477226 , 15.9687195], dtype=float32)</span>
</pre></div>
</div>
</section>
<section id="rawkernel">
<h4>RawKernel<a class="headerlink" href="#rawkernel" title="Link to this heading">¶</a></h4>
<p>The last is the RawKernel class, which is used to define kernels from raw CUDA/HIP source code.</p>
<p>RawKernel object allows you to call the kernel with CUDA’s cuLaunchKernel interface,
and this gives you control of e.g. the grid size, block size, shared memory size, and stream.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">add_kernel</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">RawKernel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&#39;&#39;</span>
<span class="gp">... </span><span class="s1">extern &quot;C&quot; __global__</span>
<span class="gp">... </span><span class="s1">void my_add(const float* x1, const float* x2, float* y) {</span>
<span class="gp">... </span><span class="s1">    int tid = blockDim.x * blockIdx.x + threadIdx.x;</span>
<span class="gp">... </span><span class="s1">    y[tid] = x1[tid] + x2[tid];</span>
<span class="gp">... </span><span class="s1">}</span>
<span class="gp">... </span><span class="s1">&#39;&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;my_add&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">add_kernel</span><span class="p">((</span><span class="mi">5</span><span class="p">,),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,),</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">array([[ 0.,  2.,  4.,  6.,  8.],</span>
<span class="go">       [10., 12., 14., 16., 18.],</span>
<span class="go">       [20., 22., 24., 26., 28.],</span>
<span class="go">       [30., 32., 34., 36., 38.],</span>
<span class="go">       [40., 42., 44., 46., 48.]], dtype=float32)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The kernel does not have return values. You need to pass
both input arrays and output arrays as arguments.</p>
<p>When using printf() in your GPU kernel, you may need to
synchronize the stream to see the output.</p>
<p>The kernel is declared in an extern “C” block,
indicating that the C linkage is used. This is to ensure
the kernel names are not mangled so that they can be retrieved by name.</p>
</div>
</section>
<section id="cupy-fuse-decorator">
<h4><code class="docutils literal notranslate"><span class="pre">cupy.fuse</span></code> decorator<a class="headerlink" href="#cupy-fuse-decorator" title="Link to this heading">¶</a></h4>
<p>Apart from using the above templates for custom kernels,
CuPy provides the <code class="docutils literal notranslate"><span class="pre">cupy.fuse</span></code> decorator which “fuse” the
custom kernel functions to a single kernel function, therefore
creating a dramatic lowering of the launching overhead.
Moreover, the syntax looks like a Numba decorator, it is
much easier to define an elementwise or reduction kernel
than using the ElementwiseKernel or ReductionKernel template.</p>
<p>However, it is still experimental, i.e. there are bugs and
incomplete functionalities to be fixed.</p>
<p>Here is the example using <code class="docutils literal notranslate"><span class="pre">cupy.fuse()</span></code> decorator</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># adding decorator to the function squared_diff</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nd">@cp</span><span class="o">.</span><span class="n">fuse</span><span class="p">(</span><span class="n">kernel_name</span><span class="o">=</span><span class="s1">&#39;squared_diff&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">def</span><span class="w"> </span><span class="nf">squared_diff</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># allocating x and y</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">cp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># call the function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">squared_diff</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">array([81, 49, 25,  9,  1,  1,  9, 25, 49, 81])</span>
</pre></div>
</div>
</section>
<section id="low-level-features">
<h4>Low-level features<a class="headerlink" href="#low-level-features" title="Link to this heading">¶</a></h4>
<p>In addition to custom kernels, accessing low-level CUDA/HIP features
are available for those who need more fine-grain control for performance:</p>
<ul class="simple">
<li><p>Stream and Event: CUDA stream and per-thread default stream are supported by all APIs</p></li>
<li><p>Memory Pool: Customizable memory allocator with a built-in memory pool</p></li>
<li><p>Profiler: Supports profiling code using CUDA Profiler and NVTX</p></li>
<li><p>Host API Binding: Directly call CUDA libraries, such as
NCCL, cuDNN, cuTENSOR, and cuSPARSELt APIs from Python</p></li>
</ul>
</section>
</section>
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Link to this heading">¶</a></h3>
<p>In this episode, we have learned about:</p>
<ul class="simple">
<li><p>CuPy basics</p></li>
<li><p>Moving data between the CPU and GPU devices</p></li>
<li><p>Different ways to launch GPU kernels</p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>GPUs have massive computing power compared to CPU</p></li>
<li><p>CuPy is a good first step to start</p></li>
<li><p>CuPy provides an extensive collection of GPU array functions</p></li>
<li><p>Always have both the CPU and GPU versions of your code available
so that you can compare performance, as well as validate the results</p></li>
<li><p>Fine-tuning for optimal performance of real-world applications can be tedioius</p></li>
</ul>
</div>
</section>
<section id="see-also">
<h3>See also<a class="headerlink" href="#see-also" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.cupy.dev/en/stable/index.html">CuPy Homepage</a></p></li>
<li><p><a class="reference external" href="https://enccs.github.io/gpu-programming">GPU programming: When, Why and How?</a></p></li>
<li><p><a class="reference external" href="https://nvidia.github.io/cuda-python/latest">CUDA Python from Nvidia</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/CuPy">CuPy Wiki page</a></p></li>
<li><p><a class="reference external" href="https://chainer.org/announcement/2019/12/05/released-v7.html">Chainer Blog</a></p></li>
</ul>
</section>
</section>
<span id="document-intohpc"></span><section id="introduction-to-hpc">
<h2>Introduction to HPC<a class="headerlink" href="#introduction-to-hpc" title="Link to this heading">¶</a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What is High-Performance Computing (HPC)?</p></li>
<li><p>Why do we use HPC systems?</p></li>
<li><p>How does parallel computing make programs faster?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Define what High-Performance Computing (HPC) is.</p></li>
<li><p>Identify the main components of an HPC system.</p></li>
<li><p>Describe the difference between serial and parallel computing.</p></li>
<li><p>Run a simple command on a cluster using the terminal.</p></li>
</ul>
</div>
<p>High-Performance Computing (HPC) refers to using many computers working
together to solve complex problems faster than a single machine could.
HPC is widely used in fields such as climate science, molecular
simulation, astrophysics, and artificial intelligence.</p>
<p>This lesson introduces what HPC is, why it matters, and how researchers
use clusters to perform large-scale computations.</p>
<hr class="docutils" />
<section id="what-is-hpc">
<h3>What is HPC?<a class="headerlink" href="#what-is-hpc" title="Link to this heading">¶</a></h3>
<p>HPC systems, often called <em>supercomputers</em> or <em>clusters</em>, are made up of
many computers (called <strong>nodes</strong>) connected by a fast network. Each node
can have multiple cores which are <strong>CPUs</strong> (and sometimes <strong>GPUs</strong>) that
run tasks in parallel.</p>
<section id="typical-hpc-components">
<h4>Typical HPC Components<a class="headerlink" href="#typical-hpc-components" title="Link to this heading">¶</a></h4>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Component</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Login node</strong></p></td>
<td><p>Where you connect and submit jobs</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Compute nodes</strong></p></td>
<td><p>Machines where your program actually runs</p></td>
</tr>
<tr class="row-even"><td><p><strong>Scheduler</strong></p></td>
<td><p>Manages job submissions and allocates resources (e.g. SLURM)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Storage</strong></p></td>
<td><p>Shared file system accessible to all nodes</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<hr class="docutils" />
<section id="single-core-performance-optimization">
<h3>Single core performance optimization<a class="headerlink" href="#single-core-performance-optimization" title="Link to this heading">¶</a></h3>
<p>Pure-Python loops are slow because each iteration runs in the Python interpreter. NumPy pushes work into optimized native code (C/C++/BLAS), drastically reducing overhead. Below we compare a Python for loop with NumPy vectorized operations and discuss tips for fair, single-core measurements.</p>
<div class="admonition-practice-making-python-faster-on-a-single-cpu exercise important admonition" id="exercise-0">
<p class="admonition-title">Practice making Python faster on a single CPU.</p>
<p>Copy and paste this code</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="c1"># (Optional safety if you run this inside Python, must be set BEFORE importing numpy)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;OMP_NUM_THREADS&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;OPENBLAS_NUM_THREADS&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;MKL_NUM_THREADS&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;NUMEXPR_NUM_THREADS&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">perf_counter</span>

<span class="k">def</span><span class="w"> </span><span class="nf">timeit</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># warmup</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup</span><span class="p">):</span>
        <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="c1"># timed runs</span>
    <span class="n">tmin</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
        <span class="n">t0</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">dt</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
        <span class="n">tmin</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">tmin</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tmin</span>

<span class="c1"># Problem size</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10_000_000</span>  <span class="c1"># 10 million elements</span>

<span class="c1"># Test data (contiguous, fixed dtype)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="c1"># --- 1) Pure-Python loop sum ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">py_sum</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>         <span class="c1"># per-element Python overhead</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">v</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="c1"># --- 2) NumPy vectorized sum ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">np_sum</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>      <span class="c1"># dispatches to optimized C/BLAS</span>

<span class="c1"># --- 3) Elementwise add then sum (Python loop) ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">py_add_sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="c1"># --- 4) Elementwise add then sum (NumPy, no temporaries) ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">np_add_sum_no_temp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># np.add.reduce avoids allocating x+y temporary</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">reduce</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>  <span class="c1"># equivalent to sum stacks; see alt below</span>

<span class="c1"># Alternative that’s typically fastest and clearer:</span>
<span class="k">def</span><span class="w"> </span><span class="nf">np_add_sum_fast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># may allocate a temporary; fast on many BLAS builds</span>

<span class="c1"># Time them</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Timing on single core (best of 5 runs):&quot;</span><span class="p">)</span>
<span class="n">t_py_sum</span>   <span class="o">=</span> <span class="n">timeit</span><span class="p">(</span><span class="n">py_sum</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
<span class="n">t_np_sum</span>   <span class="o">=</span> <span class="n">timeit</span><span class="p">(</span><span class="n">np_sum</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
<span class="n">t_py_add</span>   <span class="o">=</span> <span class="n">timeit</span><span class="p">(</span><span class="n">py_add_sum</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">t_np_add</span>   <span class="o">=</span> <span class="n">timeit</span><span class="p">(</span><span class="n">np_add_sum_fast</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python for-loop sum:          </span><span class="si">{</span><span class="n">t_py_sum</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NumPy vectorized sum:         </span><span class="si">{</span><span class="n">t_np_sum</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python loop add+sum:          </span><span class="si">{</span><span class="n">t_py_add</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NumPy vectorized add+sum:     </span><span class="si">{</span><span class="n">t_np_add</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2"> s&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Execute it and following let us verify the effect on the following modifications:</p>
<ol class="arabic simple">
<li><p>Run the timing script with N = 1_000_000, 5_000_000, 20_000_000.</p></li>
<li><p>Try float32 vs float64.</p></li>
<li><p>Switch (a + b).sum() to np.add(a, b, out=a); a.sum() and compare.</p></li>
</ol>
</div>
<section id="practical-tips-for-single-core-speed">
<h4>Practical tips for single-core speed<a class="headerlink" href="#practical-tips-for-single-core-speed" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Prefer vectorization: Use array ops (+, <em>, .sum(), .dot(), np.mean, np.linalg.</em>) rather than per-element Python loops.</p></li>
<li><p>Control temporaries: Expressions like (a + b + c).sum() may create temporaries. When memory is tight, consider in-place ops (a += b) or reductions (np.add(a, b, out=a); np.add.reduce([…])).</p></li>
<li><p>Use the right dtype: float64 is standard for numerics; float32 halves memory traffic and can be faster on some CPUs/GPUs (but mind precision).</p></li>
<li><p>Preallocate: Avoid growing Python lists or repeatedly allocating arrays inside loops.</p></li>
<li><p>Minimize Python in hot paths: Move heavy math into NumPy calls; keep Python for orchestration only.</p></li>
<li><p>Benchmark correctly: Use large N, pin threads to 1 for fair single-core tests, and report the best of multiple runs after a warmup.</p></li>
</ul>
<p>–</p>
</section>
</section>
<section id="parallel-computing">
<h3>Parallel Computing<a class="headerlink" href="#parallel-computing" title="Link to this heading">¶</a></h3>
<p>High-Performance Computing relies on <strong>parallel computing</strong>, splitting a problem into smaller parts that can be executed <em>simultaneously</em> on multiple processors.</p>
<p>Instead of running one instruction at a time on one CPU core, parallel computing allows you to run many instructions on many cores or even multiple machines at once.</p>
<p>Parallelism can occur at different levels:</p>
<ul class="simple">
<li><p><strong>Within a single CPU</strong> (multiple cores)</p></li>
<li><p><strong>Across multiple CPUs</strong> (distributed nodes)</p></li>
<li><p><strong>On specialized accelerators</strong> (GPUs or TPUs)</p></li>
</ul>
<hr class="docutils" />
<section id="shared-memory-parallelism">
<h4>Shared-Memory Parallelism<a class="headerlink" href="#shared-memory-parallelism" title="Link to this heading">¶</a></h4>
<p>In <strong>shared-memory</strong> systems, multiple processor cores share the same memory space.<br />
Each core can directly read and write to the same variables in memory.</p>
<p>This is the model used in:</p>
<ul class="simple">
<li><p>Multicore laptops and workstations</p></li>
<li><p><em>Single compute nodes</em> on a cluster</p></li>
</ul>
<p>Programs use <strong>threads</strong> to execute in parallel (e.g., with OpenMP in C/C++/Fortran or <strong>multiprocessing in Python</strong>).</p>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<p>Advantages:</p>
<ul class="simple">
<li><p>Easy communication between threads (shared variables)</p></li>
<li><p>Low latency data access</p></li>
</ul>
<p>Limitations:</p>
<ul class="simple">
<li><p>Limited by the number of cores on one machine</p></li>
<li><p>Risk of race conditions if data access is not synchronized</p></li>
</ul>
</div>
<div class="admonition-practice-with-threaded-parallelism-in-python exercise important admonition" id="exercise-1">
<p class="admonition-title">Practice with threaded parallelism in Python</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">multiprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pool</span>

<span class="k">def</span><span class="w"> </span><span class="nf">square</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">Pool</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">square</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="distributed-memory-parallelism">
<h4>Distributed-Memory Parallelism<a class="headerlink" href="#distributed-memory-parallelism" title="Link to this heading">¶</a></h4>
<p>In distributed-memory systems, each processor (or node) has its own local memory.
Processors communicate by passing messages over a network.</p>
<p>This is the model used when a computation spans multiple nodes in an HPC cluster.</p>
<p>Programs written with MPI (Message Passing Interface) use explicit communication.
Below is an example using the Python library <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> that implements MPI functions
in Python</p>
<div class="admonition-practice-with-a-simple-mpi-program exercise important admonition" id="exercise-2">
<p class="admonition-title">Practice with a simple MPI program</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># hello_mpi.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="c1"># Initialize the MPI communicator</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>

<span class="c1"># Get the total number of processes</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="c1"># Get the rank (ID) of this process</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Hello from process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># MPI is automatically finalized when the program exits,</span>
<span class="c1"># but you can call MPI.Finalize() explicitly if you prefer</span>
</pre></div>
</div>
</div>
<p>For now, do not worry about understanding this code, we will see
<code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> in detail later.</p>
<div class="admonition-keypoints keypoints admonition" id="keypoints-1">
<p class="admonition-title">Keypoints</p>
<p>Advantages:</p>
<ul class="simple">
<li><p>Scales to thousands of nodes</p></li>
<li><p>Each process works independently, avoiding memory contention</p></li>
</ul>
<p>Limitations:</p>
<ul class="simple">
<li><p>Requires explicit communication (send/receive)</p></li>
<li><p>More complex programming model</p></li>
<li><p>More latency, requires minimizing movement of data.</p></li>
</ul>
</div>
</section>
<section id="hybrid-architectures-cpu-gpu-and-tpu">
<h4>Hybrid Architectures: CPU, GPU, and TPU<a class="headerlink" href="#hybrid-architectures-cpu-gpu-and-tpu" title="Link to this heading">¶</a></h4>
<p>Modern High-Performance Computing (HPC) systems rarely rely on CPUs alone.<br />
They are <strong>hybrid architectures</strong>, combining different types of processors, typically <strong>CPUs</strong>, <strong>GPUs</strong>, and increasingly <strong>TPUs</strong>, to achieve both flexibility and high performance.</p>
<hr class="docutils" />
<section id="cpu-the-general-purpose-processor">
<h5>CPU: The General-Purpose Processor<a class="headerlink" href="#cpu-the-general-purpose-processor" title="Link to this heading">¶</a></h5>
<p><strong>Central Processing Units (CPUs)</strong> are versatile processors capable of handling a wide range of tasks.<br />
They consist of a small number of powerful cores optimized for complex, sequential operations and control flow.</p>
<p>CPUs are responsible for:</p>
<ul class="simple">
<li><p>Managing input/output operations</p></li>
<li><p>Coordinating data movement and workflow</p></li>
<li><p>Executing serial portions of applications</p></li>
</ul>
<p>They excel in <strong>task parallelism</strong>, where different cores perform distinct tasks concurrently.</p>
</section>
<hr class="docutils" />
<section id="gpu-the-parallel-workhorse">
<h5>GPU: The Parallel Workhorse<a class="headerlink" href="#gpu-the-parallel-workhorse" title="Link to this heading">¶</a></h5>
<p><strong>Graphics Processing Units (GPUs)</strong> contain thousands of lightweight cores that can execute the same instruction on many data elements simultaneously.<br />
This makes them ideal for <strong>data-parallel</strong> workloads, such as numerical simulations, molecular dynamics, and deep learning.</p>
<p>GPUs are optimized for:</p>
<ul class="simple">
<li><p>Large-scale mathematical computations</p></li>
<li><p>Highly parallel tasks such as matrix and vector operations</p></li>
</ul>
<p>Common GPU computing frameworks include CUDA, HIP, OpenACC, and SYCL.</p>
<p>GPUs provide massive computational throughput but require explicit management of data transfers between CPU and GPU memory.<br />
They are now a standard component of most modern supercomputers.</p>
</section>
<hr class="docutils" />
<section id="tpu-specialized-processor-for-tensor-operations">
<h5>TPU: Specialized Processor for Tensor Operations<a class="headerlink" href="#tpu-specialized-processor-for-tensor-operations" title="Link to this heading">¶</a></h5>
<p><strong>Tensor Processing Units (TPUs)</strong> are specialized hardware accelerators designed for tensor and matrix operations, the building blocks of deep learning and AI.<br />
Originally developed by Google, TPUs are now used in both cloud and research HPC environments.</p>
<p>TPUs focus on <strong>tensor computations</strong> and achieve very high performance and energy efficiency for machine learning workloads.<br />
They are less flexible than CPUs or GPUs but excel in neural network training and inference.</p>
</section>
</section>
</section>
<section id="python-in-high-performance-computing">
<h3>Python in High-Performance Computing<a class="headerlink" href="#python-in-high-performance-computing" title="Link to this heading">¶</a></h3>
<p>Python has become one of the most widely used languages in scientific computing due to its simplicity, readability, and extensive ecosystem of numerical libraries.<br />
Although Python itself is interpreted and slower than compiled languages such as C or Fortran, it now provides a mature set of tools that allow code to <strong>run efficiently on modern HPC architectures</strong>.</p>
<p>These tools map directly to the three fundamental forms of parallelism introduced earlier:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>HPC Parallelism Type</p></th>
<th class="head"><p>Hardware Context</p></th>
<th class="head"><p>Python Solutions</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Shared-memory parallelism</strong></p></td>
<td><p>Multicore CPUs within a node</p></td>
<td><p>NumPy, Numba, Pythran</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Distributed-memory parallelism</strong></p></td>
<td><p>Multiple nodes across a cluster</p></td>
<td><p>mpi4py</p></td>
</tr>
<tr class="row-even"><td><p><strong>Accelerator parallelism</strong></p></td>
<td><p>GPUs and TPUs</p></td>
<td><p>CuPy, JAX, Numba (CUDA)</p></td>
</tr>
</tbody>
</table>
</div>
<p>In practice, these technologies allow Python programs to scale from a single core to thousands of nodes on hybrid CPU–GPU systems.</p>
<hr class="docutils" />
<section id="shared-memory-parallelism-multicore-cpus">
<h4>Shared-Memory Parallelism (Multicore CPUs)<a class="headerlink" href="#shared-memory-parallelism-multicore-cpus" title="Link to this heading">¶</a></h4>
<p>Shared-memory parallelism occurs within a single compute node, where all CPU cores access the same physical memory.<br />
Python supports this level of performance primarily through <strong>compiled numerical libraries</strong> and <strong>JIT (Just-In-Time) compilation</strong>, which transform slow Python loops into efficient native machine code.</p>
<section id="numpy-foundation-of-scientific-computing">
<h5>NumPy: Foundation of Scientific Computing<a class="headerlink" href="#numpy-foundation-of-scientific-computing" title="Link to this heading">¶</a></h5>
<p><strong>NumPy</strong> provides fast array operations implemented in C and Fortran.<br />
Its vectorized operations and BLAS/LAPACK backends <strong>automatically</strong> exploit shared-memory parallelism through optimized linear algebra kernels.<br />
Although users write Python, most computations occur in compiled native code.</p>
</section>
<section id="pythran-static-compilation-of-numerical-python-code">
<h5>Pythran: Static Compilation of Numerical Python Code<a class="headerlink" href="#pythran-static-compilation-of-numerical-python-code" title="Link to this heading">¶</a></h5>
<p><strong>Pythran</strong> compiles numerical Python code — particularly code using NumPy — into optimized C++ extensions.<br />
It can automatically parallelize loops using <strong>OpenMP</strong>, enabling true multicore utilization without manual thread management.</p>
<p>Key strengths:</p>
<ul class="simple">
<li><p>Converts array-oriented Python functions into C++ for near-native speed</p></li>
<li><p>Supports automatic OpenMP parallelization for CPU cores</p></li>
<li><p>Integrates easily into existing Python workflows</p></li>
</ul>
<p>Pythran is well-suited for simulations or kernels that need to exploit multiple cores on a node.</p>
</section>
<section id="numba-jit-compilation-for-shared-and-accelerator-architectures">
<h5>Numba: JIT Compilation for Shared and Accelerator Architectures<a class="headerlink" href="#numba-jit-compilation-for-shared-and-accelerator-architectures" title="Link to this heading">¶</a></h5>
<p><strong>Numba</strong> uses LLVM to JIT-compile Python functions into efficient machine code at runtime.<br />
On multicore CPUs, Numba can parallelize loops using OpenMP-like constructs; on GPUs, it can emit CUDA kernels (see below).</p>
<p>Main advantages:</p>
<ul class="simple">
<li><p>Minimal syntax changes required</p></li>
<li><p>Explicit parallel decorators for CPU threading</p></li>
<li><p>Compatible with NumPy arrays and ufuncs</p></li>
</ul>
<p>Together, NumPy, Pythran, and Numba enable Python to fully exploit shared-memory parallelism.</p>
</section>
</section>
<hr class="docutils" />
<section id="distributed-memory-parallelism-clusters-and-supercomputers">
<h4>Distributed-Memory Parallelism (Clusters and Supercomputers)<a class="headerlink" href="#distributed-memory-parallelism-clusters-and-supercomputers" title="Link to this heading">¶</a></h4>
<p>At large scale, HPC systems use <strong>distributed memory</strong>, where each node has its own local memory and must communicate explicitly.<br />
Python provides access to this level of parallelism through <strong>mpi4py</strong>, a direct interface to the standard MPI library.</p>
<section id="mpi4py-scalable-distributed-computing-with-mpi">
<h5>mpi4py: Scalable Distributed Computing with MPI<a class="headerlink" href="#mpi4py-scalable-distributed-computing-with-mpi" title="Link to this heading">¶</a></h5>
<p><strong>mpi4py</strong> enables Python programs to exchange data between processes running on different nodes using MPI.<br />
It provides both point-to-point and collective communication primitives, identical in concept to those used in C or Fortran MPI applications.</p>
<p>Key features:</p>
<ul class="simple">
<li><p>Works seamlessly with NumPy arrays (zero-copy data transfer)</p></li>
<li><p>Supports all MPI operations (send, receive, broadcast, scatter, gather, reduce)</p></li>
<li><p>Compatible with job schedulers such as SLURM or PBS</p></li>
</ul>
<p>With <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code>, Python can participate in large-scale distributed-memory simulations or data-parallel tasks across thousands of cores.</p>
</section>
</section>
<hr class="docutils" />
<section id="accelerator-specific-parallelism-gpus-and-tpus">
<h4>Accelerator-Specific Parallelism (GPUs and TPUs)<a class="headerlink" href="#accelerator-specific-parallelism-gpus-and-tpus" title="Link to this heading">¶</a></h4>
<p>Modern HPC nodes increasingly include <strong>GPUs</strong> or <strong>TPUs</strong> to accelerate numerical workloads.<br />
Python offers several mature libraries that interface directly with these accelerators, providing high-level syntax while executing low-level parallel kernels.</p>
<section id="cupy-gpu-accelerated-numpy-replacement">
<h5>CuPy: GPU-Accelerated NumPy Replacement<a class="headerlink" href="#cupy-gpu-accelerated-numpy-replacement" title="Link to this heading">¶</a></h5>
<p><strong>CuPy</strong> mirrors the NumPy API but executes array operations on GPUs using CUDA (NVIDIA) or ROCm (AMD).<br />
Users can port existing NumPy code to GPUs with minimal changes, gaining massive speedups for large, data-parallel computations.</p>
<p>Highlights:</p>
<ul class="simple">
<li><p>NumPy-compatible array and linear algebra operations</p></li>
<li><p>Native support for multi-GPU and CUDA streams</p></li>
<li><p>Tight integration with deep learning and simulation frameworks</p></li>
</ul>
</section>
<section id="jax-unified-array-computing-for-cpus-gpus-and-tpus">
<h5>JAX: Unified Array Computing for CPUs, GPUs, and TPUs<a class="headerlink" href="#jax-unified-array-computing-for-cpus-gpus-and-tpus" title="Link to this heading">¶</a></h5>
<p><strong>JAX</strong> combines automatic differentiation and XLA-based compilation to execute Python functions efficiently on CPUs, GPUs, and TPUs.<br />
It is particularly well-suited for scientific machine learning and differentiable simulations.</p>
<p>Key strengths:</p>
<ul class="simple">
<li><p>Just-In-Time (JIT) compilation via XLA</p></li>
<li><p>Transparent execution on accelerators (GPU, TPU)</p></li>
<li><p>Built-in vectorization and automatic differentiation</p></li>
</ul>
<p>JAX provides a single high-level API for heterogeneous HPC nodes, seamlessly handling hybrid CPU–GPU–TPU workflows.</p>
</section>
</section>
<hr class="docutils" />
<section id="summary-python-across-hpc-architectures">
<h4>Summary: Python Across HPC Architectures<a class="headerlink" href="#summary-python-across-hpc-architectures" title="Link to this heading">¶</a></h4>
<p>Python can now leverage <strong>all layers of hybrid HPC architectures</strong> through specialized libraries:</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Architecture</p></th>
<th class="head"><p>Parallelism Type</p></th>
<th class="head"><p>Typical Python Tools</p></th>
<th class="head"><p>Example Use Cases</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Multicore CPUs</strong></p></td>
<td><p>Shared memory</p></td>
<td><p>NumPy, Pythran, Numba</p></td>
<td><p>Numerical kernels, vectorized math</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clusters</strong></p></td>
<td><p>Distributed memory</p></td>
<td><p>mpi4py</p></td>
<td><p>Large-scale simulations, domain decomposition</p></td>
</tr>
<tr class="row-even"><td><p><strong>GPUs / TPUs</strong></p></td>
<td><p>Accelerator parallelism</p></td>
<td><p>CuPy, JAX, Numba (CUDA)</p></td>
<td><p>Machine learning, dense linear algebra</p></td>
</tr>
</tbody>
</table>
</div>
<p>Together, these tools allow Python to serve as a <em>high-level orchestration language</em> that transparently scales from a single laptop core to full supercomputing environments — integrating shared-memory, distributed-memory, and accelerator-based parallelism in one ecosystem.</p>
<hr class="docutils" />
<div class="admonition-keypoints keypoints admonition" id="keypoints-2">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Python’s ecosystem maps naturally onto hybrid HPC architectures.</p></li>
<li><p><strong>NumPy, Numba, and Pythran</strong> exploit shared-memory parallelism on multicore CPUs.</p></li>
<li><p><strong>mpi4py</strong> extends Python to distributed-memory clusters.</p></li>
<li><p><strong>CuPy and JAX</strong> enable acceleration on GPUs and TPUs.</p></li>
<li><p>These libraries allow researchers to combine high productivity with near-native performance across all layers of HPC systems.</p></li>
</ul>
</div>
</section>
</section>
</section>
<span id="document-mpi4py"></span><section id="introduction-to-mpi-with-python-mpi4py">
<h2>Introduction to MPI with Python (mpi4py)<a class="headerlink" href="#introduction-to-mpi-with-python-mpi4py" title="Link to this heading">¶</a></h2>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>What is MPI, and how does it enable parallel programs to communicate?</p></li>
<li><p>How does Python implement MPI through the <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> library?</p></li>
<li><p>What are point-to-point and collective communications?</p></li>
<li><p>How does <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> integrate with NumPy for efficient data exchange?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand the conceptual model of MPI: processes, ranks, and communication.</p></li>
<li><p>Distinguish between point-to-point and collective operations.</p></li>
<li><p>Recognize how NumPy arrays act as communication buffers in <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code>.</p></li>
<li><p>See how <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> bridges Python and traditional HPC concepts.</p></li>
</ul>
</div>
<hr class="docutils" />
<section id="what-is-mpi">
<h3>What Is MPI?<a class="headerlink" href="#what-is-mpi" title="Link to this heading">¶</a></h3>
<p><strong>MPI (Message Passing Interface)</strong> is a standardized programming model for communication among processes that run on <strong>distributed-memory systems</strong>, such as HPC clusters.</p>
<p>In a distributed-memory system, each compute node (or process) has its <strong>own local memory</strong>.<br />
Unlike shared-memory systems, where threads can directly read and write to a common address space, distributed processes <strong>cannot directly access each other’s memory</strong>.<br />
To collaborate, they must explicitly <strong>send and receive messages</strong> containing the data they need to share.</p>
<section id="independent-processes-and-the-spmd-model">
<h4>Independent Processes and the SPMD Model<a class="headerlink" href="#independent-processes-and-the-spmd-model" title="Link to this heading">¶</a></h4>
<p>When you run an MPI program, the system launches <strong>multiple independent processes</strong>, each running its <strong>own copy</strong> of the same program.<br />
This design is fundamental: because each process owns its own memory space, it must contain its own copy of the code to execute its portion of the computation.</p>
<p>Each process:</p>
<ul class="simple">
<li><p>Runs the same code but operates on a different subset of the data.</p></li>
<li><p>Is identified by a unique number called its <strong>rank</strong>.</p></li>
<li><p>Belongs to a <strong>communicator</strong>, a group of processes that can exchange messages (most commonly <code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD</span></code>).</p></li>
</ul>
<p>This model is known as <strong>SPMD: Single Program, Multiple Data</strong>:<br />
a single source program runs simultaneously on many processes, each working on different data.</p>
</section>
<section id="why-copies-of-the-program-are-needed">
<h4>Why Copies of the Program Are Needed?<a class="headerlink" href="#why-copies-of-the-program-are-needed" title="Link to this heading">¶</a></h4>
<p>Because processes in distributed memory do not share variables or memory addresses, each process must have:</p>
<ul class="simple">
<li><p>Its <strong>own copy of the executable code</strong>, and</p></li>
<li><p>Its <strong>own private workspace (variables, arrays, etc.)</strong>.</p></li>
</ul>
<p>This independence is crucial for scalability:</p>
<ul class="simple">
<li><p>Each process can execute independently without memory contention.</p></li>
<li><p>The program can scale to thousands of nodes, since no shared memory bottleneck exists.</p></li>
<li><p>Data movement becomes explicit and controllable, ensuring predictable performance on large clusters.</p></li>
</ul>
</section>
<section id="sharing-data-between-processes">
<h4>Sharing Data Between Processes<a class="headerlink" href="#sharing-data-between-processes" title="Link to this heading">¶</a></h4>
<p>Although memory is not shared, processes can <strong>cooperate</strong> by exchanging information through <strong>message passing</strong>.<br />
MPI defines two main communication mechanisms:</p>
<ol class="arabic simple">
<li><p><strong>Point-to-point communication</strong>: Data moves <strong>directly</strong> between two processes.</p></li>
<li><p><strong>Collective communication</strong>: Data is exchanged among <strong>all processes</strong> in a communicator in a coordinated way.</p></li>
</ol>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p><strong>Process:</strong> Each MPI program runs as multiple independent processes, not threads.</p></li>
<li><p><strong>Rank:</strong> Every process has a unique identifier (its <em>rank</em>) within a communicator, used to distinguish and coordinate them.</p></li>
<li><p><strong>Communication:</strong> Processes exchange data explicitly through message passing, either <strong>point-to-point</strong> (between pairs) or <strong>collective</strong> (among groups).</p></li>
</ul>
<p>Together, these three ideas form the foundation of MPI’s model for parallel computing.</p>
</div>
</section>
</section>
<hr class="docutils" />
<section id="mpi4py">
<h3>mpi4py<a class="headerlink" href="#mpi4py" title="Link to this heading">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> is the standard Python interface to the <strong>Message Passing Interface (MPI)</strong>, the same API used by C, C++, and Fortran codes for distributed-memory parallelism.<br />
It allows Python programs to run on many processes, each with its own memory space, communicating through explicit messages.</p>
<section id="communicators-and-initialization">
<h4>Communicators and Initialization<a class="headerlink" href="#communicators-and-initialization" title="Link to this heading">¶</a></h4>
<p>In MPI, all communication occurs through a <strong>communicator</strong>, an object that defines which processes can talk to each other.<br />
When a program starts, each process automatically becomes part of a predefined communicator called <strong><code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD</span></code></strong>.</p>
<p>This object represents <em>all processes</em> that were launched together by <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> or <code class="docutils literal notranslate"><span class="pre">srun</span></code>.</p>
<p>A typical initialization pattern looks like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>      <span class="c1"># Initialize communicator</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>     <span class="c1"># Total number of processes</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>     <span class="c1"># Rank (ID) of this process</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;I am rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Every process executes the same code, but rank and size allow them to behave differently.</p>
<div class="admonition-hello-world-mpi exercise important admonition" id="exercise-0">
<p class="admonition-title">Hello world MPI</p>
<p>Copy and paste this code and execute it using <code class="docutils literal notranslate"><span class="pre">mpirun</span> <span class="pre">-n</span> <span class="pre">N</span> <span class="pre">mpi_hello.py</span></code> where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of tasks. <br />
<strong>Note:</strong> Do not put more tasks than the number of cores that your computer has.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_hello.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="c1"># Initialize communicator</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>

<span class="c1"># Get the number of processes</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="c1"># Get the rank (ID) of this process</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="c1"># Print a message from each process</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Hello world&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This code snippet illustrates how independent processes run copies of the program. <br />
To practice further try the following:</p>
<ol class="arabic simple">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">rank</span></code> variable to print the square of <code class="docutils literal notranslate"><span class="pre">rank</span></code> in each rank.</p></li>
<li><p>Make the program print only in rank 0, hint: <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">rank</span> <span class="pre">==</span> <span class="pre">0:</span></code></p></li>
</ol>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<p><em>Solution 1:</em> Print the square of each rank</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_hello_square.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="c1"># Each process prints its rank and the square of its rank</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2"> has value </span><span class="si">{</span><span class="n">rank</span><span class="o">**</span><span class="mi">2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><em>Solution 2:</em> Print only one process (rank 0)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_hello_rank0.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Hello world from the root process (rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">) out of </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2"> total processes&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="method-naming-convention">
<h4>Method Naming Convention<a class="headerlink" href="#method-naming-convention" title="Link to this heading">¶</a></h4>
<p>In <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code>, most MPI operations exist in <strong>two versions</strong>, a <em>lowercase</em> and an <em>uppercase</em> form, that differ in how they handle data.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Convention</p></th>
<th class="head"><p>Example</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Lowercase methods</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">send()</span></code>, <code class="docutils literal notranslate"><span class="pre">recv()</span></code>, <code class="docutils literal notranslate"><span class="pre">bcast()</span></code>, <code class="docutils literal notranslate"><span class="pre">gather()</span></code></p></td>
<td><p>High-level, Pythonic methods that can send and receive arbitrary Python objects. Data is automatically serialized (pickled). Simpler to use but slower for large data.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Uppercase methods</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Send()</span></code>, <code class="docutils literal notranslate"><span class="pre">Recv()</span></code>, <code class="docutils literal notranslate"><span class="pre">Bcast()</span></code>, <code class="docutils literal notranslate"><span class="pre">Gather()</span></code></p></td>
<td><p>Low-level, performance-oriented methods that operate on <strong>buffer-like objects</strong> such as NumPy arrays. Data is transferred directly from memory without serialization, achieving near-C speed.</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Rule of thumb:</strong><br />
Use <em>lowercase</em> methods for small control messages or Python objects,<br />
and <em>uppercase</em> methods for numerical data stored in arrays when performance matters.</p>
<section id="syntax-differences">
<h5>Syntax differences<a class="headerlink" href="#syntax-differences" title="Link to this heading">¶</a></h5>
<p><strong>Lowercase (Python objects):</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The message (obj) can be any Python object.</p></li>
<li><p>MPI automatically serializes and deserializes it internally.</p></li>
<li><p>Fewer arguments: simple but less efficient for large data.</p></li>
</ul>
<p><strong>Uppercase (buffer-like objects, e.g., NumPy arrays):</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">comm</span><span class="o">.</span><span class="n">Send</span><span class="p">([</span><span class="n">array</span><span class="p">,</span> <span class="n">MPI</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">],</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">comm</span><span class="o">.</span><span class="n">Recv</span><span class="p">([</span><span class="n">array</span><span class="p">,</span> <span class="n">MPI</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">],</span> <span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Requires explicit definition of the data buffer and its MPI datatype. (same syntax as C++)</p></li>
<li><p>Works directly with the memory address of the array (no serialization).</p></li>
<li><p>Achieves maximum throughput for numerical and scientific workloads.</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="point-to-point-communication">
<h3>Point-to-Point Communication<a class="headerlink" href="#point-to-point-communication" title="Link to this heading">¶</a></h3>
<p>The most basic form of communication in MPI is <strong>point-to-point</strong>, meaning data is sent from one process directly to another.</p>
<p>Each message involves:</p>
<ul class="simple">
<li><p>A <strong>sender</strong> and a <strong>receiver</strong></p></li>
<li><p>A <strong>tag</strong> identifying the message type</p></li>
<li><p>A <strong>data buffer</strong> that holds the information being transmitted</p></li>
</ul>
<p>These operations are methods of the class <code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD</span></code>. This means that one needs to initialize it</p>
<p>Typical operations:</p>
<ul class="simple">
<li><p><strong>Send:</strong> one process transmits data.</p></li>
<li><p><strong>Receive:</strong> another process waits for that data.</p></li>
</ul>
<p>In <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code>, each of these operations maps directly to MPI’s underlying mechanisms but with a simple Python interface.<br />
Conceptually, this allows one process to hand off a message to another in a fully parallel environment.</p>
<p>Examples of conceptual use cases:</p>
<ul class="simple">
<li><p>Distributing different chunks of data to multiple workers.</p></li>
<li><p>Passing boundary conditions between neighboring domains in a simulation.</p></li>
</ul>
<div class="admonition-point-to-point-communication exercise important admonition" id="exercise-1">
<p class="admonition-title">Point-to-Point Communication</p>
<p>Copy and paste the code below into a file called <code class="docutils literal notranslate"><span class="pre">mpi_send_recv.py</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_send_recv.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Process 0 sends a message</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s2">&quot;Hello from process 0&quot;</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># send to process 1</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> sent data: </span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="c1"># Process 1 receives a message</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># receive from process 0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received data: </span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Other ranks do nothing</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> is idle&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Run the program using:
<code class="docutils literal notranslate"><span class="pre">mpirun</span> <span class="pre">-n</span> <span class="pre">3</span> <span class="pre">python</span> <span class="pre">mpi_send_recv.py</span></code>
You should see output indicating that process 0 sent data and process 1 received it, while all others remained idle.
Now try:</p>
<ol class="arabic simple">
<li><p>Change the roles:
Make process 1 send a reply back to process 0 after receiving the message.
Use <code class="docutils literal notranslate"><span class="pre">comm.send()</span></code> and <code class="docutils literal notranslate"><span class="pre">comm.recv()</span></code> in both directions.</p></li>
<li><p>Blocking communication:
Notice that <code class="docutils literal notranslate"><span class="pre">comm.send()</span></code> and <code class="docutils literal notranslate"><span class="pre">comm.recv()</span></code> are blocking operations.</p></li>
</ol>
<ul class="simple">
<li><p>Add a short delay using <code class="docutils literal notranslate"><span class="pre">time.sleep(rank)</span></code> before sending or receiving.</p></li>
<li><p>Observe how process 0 must wait until process 1 calls <code class="docutils literal notranslate"><span class="pre">recv()</span></code> before it can continue, and vice versa.</p></li>
<li><p>Try swapping the order of the calls (e.g., both processes call <code class="docutils literal notranslate"><span class="pre">send()</span></code> first), what happens?</p></li>
<li><p>You may notice the program hangs or deadlocks, because both processes are waiting for a <code class="docutils literal notranslate"><span class="pre">recv()</span></code> that never starts.</p></li>
</ul>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<p><em>Solution 1:</em> Change the roles (reply back):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_send_recv_reply.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">data_out</span> <span class="o">=</span> <span class="s2">&quot;Hello from process 0&quot;</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">data_out</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> sent: </span><span class="si">{</span><span class="n">data_out</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">data_in</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received: </span><span class="si">{</span><span class="n">data_in</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">data_in</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received: </span><span class="si">{</span><span class="n">data_in</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">data_out</span> <span class="o">=</span> <span class="s2">&quot;Reply from process 1&quot;</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">data_out</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> sent: </span><span class="si">{</span><span class="n">data_out</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> is idle&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><em>Solution 2:</em> Blocking communication behavior:</p>
<ol class="arabic simple">
<li><p>Add a delay (e.g., time.sleep(rank)) before send/recv and observe that each blocking call waits for its partner. Example:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_blocking_delay.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>  <span class="c1"># stagger arrival</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="s2">&quot;msg&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;0 -&gt; sent&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;0 -&gt; got:&quot;</span><span class="p">,</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1 -&gt; got:&quot;</span><span class="p">,</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="s2">&quot;ack&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1 -&gt; sent&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Deadlock demonstration:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_deadlock.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Both ranks call send() first -&gt; potential deadlock</span>
    <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;from </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">rank</span><span class="p">)</span>
    <span class="c1"># This recv may never be reached if partner is also stuck in send()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;received:&quot;</span><span class="p">,</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="n">rank</span><span class="p">))</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="collective-communication">
<h3>Collective Communication<a class="headerlink" href="#collective-communication" title="Link to this heading">¶</a></h3>
<p>While point-to-point operations handle pairs of processes, <strong>collective operations</strong> involve all processes in a communicator.<br />
They provide coordinated data exchange and synchronization patterns that are efficient and scalable.</p>
<p>Common collectives include:</p>
<ul class="simple">
<li><p><strong>Broadcast:</strong> One process sends data to all others.</p></li>
<li><p><strong>Scatter:</strong> One process distributes distinct pieces of data to each process.</p></li>
<li><p><strong>Gather:</strong> Each process sends data back to a root process.</p></li>
<li><p><strong>Reduce:</strong> All processes combine results using an operation (e.g., sum, max).</p></li>
</ul>
<p>Collectives are conceptually similar to group conversations, where every participant either contributes, receives, or both.<br />
They are essential for algorithms that require sharing intermediate results or aggregating outputs.</p>
<div class="admonition-collectives exercise important admonition" id="exercise-2">
<p class="admonition-title">Collectives</p>
<p>Let us run this code to see the collectives <code class="docutils literal notranslate"><span class="pre">bcast</span></code> and <code class="docutils literal notranslate"><span class="pre">gather</span></code> in action:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_collectives.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="c1"># --- Broadcast example ---</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s2">&quot;Hello from the root process&quot;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># Broadcast data from process 0 to all others</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received: </span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># --- Gather example ---</span>
<span class="c1"># Each process creates its own message</span>
<span class="n">local_msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Message from process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="c1"># Gather all messages at the root process (rank 0)</span>
<span class="n">all_msgs</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">local_msg</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Gathered messages at root:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">all_msgs</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</pre></div>
</div>
<p>Now try the following:</p>
<ol class="arabic simple">
<li><p>Change the root process: In the broadcast section, change the root process from <code class="docutils literal notranslate"><span class="pre">rank</span> <span class="pre">0</span></code> to <code class="docutils literal notranslate"><span class="pre">rank</span> <span class="pre">1</span></code>.</p></li>
<li><p>How would be the same done with point to point communication?</p></li>
</ol>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-2">
<p class="admonition-title">Solution</p>
<p><em>Solution 1:</em> Change the root process:
The root process is the one that handles the behaviour of the collectives. So we just need to change the root
of the collective <strong>broadcast</strong>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Broadcast example ---</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s2">&quot;Hello from process 1 (new root)&quot;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># Broadcast data from process 1 to all others</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received: </span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><em>Solution 2:</em> Manual broadcasting the previous code:
To reproduce a broadcast manually using only send() and recv(), one could write:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Manual broadcast using point-to-point</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s2">&quot;Hello from process 1 (manual broadcast)&quot;</span>
    <span class="c1"># Send to all other processes</span>
    <span class="k">for</span> <span class="n">dest</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dest</span> <span class="o">!=</span> <span class="n">rank</span><span class="p">:</span>
            <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="n">dest</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Process </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> received: </span><span class="si">{</span><span class="n">data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="integration-with-numpy-buffer-like-objects">
<h3>Integration with NumPy: Buffer-Like Objects<a class="headerlink" href="#integration-with-numpy-buffer-like-objects" title="Link to this heading">¶</a></h3>
<p>A major strength of <code class="docutils literal notranslate"><span class="pre">mpi4py</span></code> is its <strong>direct integration with NumPy arrays</strong>.<br />
MPI operations can send and receive <strong>buffer-like objects</strong>, such as NumPy arrays, without copying data between Python and C memory.</p>
<div class="admonition-important keypoints admonition" id="keypoints-1">
<p class="admonition-title">Important</p>
<p>Remember that <strong>buffer-like objects</strong> can be used with the <strong>uppercase methods</strong> for avoiding serialization and its time overhead.</p>
</div>
<p>Because NumPy arrays expose their internal memory buffer, MPI can access this data directly.<br />
This eliminates the need for serialization (no <code class="docutils literal notranslate"><span class="pre">pickle</span></code> step) and allows <strong>near-native C performance</strong> for communication and collective operations.</p>
<p>Conceptually:</p>
<ul class="simple">
<li><p>Each NumPy array acts as a <strong>contiguous memory buffer</strong>.</p></li>
<li><p>MPI transfers data directly from this buffer to another process’s memory.</p></li>
<li><p>This mechanism is ideal for large numerical datasets, enabling efficient data movement in parallel programs.</p></li>
</ul>
<p>This integration makes it possible to:</p>
<ul class="simple">
<li><p>Distribute large datasets across processes using <strong>collectives</strong> like <code class="docutils literal notranslate"><span class="pre">Scatter</span></code> and <code class="docutils literal notranslate"><span class="pre">Gather</span></code>.</p></li>
<li><p>Combine results efficiently with operations like <code class="docutils literal notranslate"><span class="pre">Reduce</span></code> or <code class="docutils literal notranslate"><span class="pre">Allreduce</span></code>.</p></li>
<li><p>Seamlessly integrate parallelism into scientific Python workflows.</p></li>
</ul>
<hr class="docutils" />
<div class="admonition-collective-operations-on-numpy-arrays exercise important admonition" id="exercise-3">
<p class="admonition-title">Collective Operations on NumPy Arrays</p>
<p>In this example, you will see how collective MPI operations distribute and combine large arrays across multiple processes using <strong>buffer-based communication</strong>.</p>
<p>Save the following code as <code class="docutils literal notranslate"><span class="pre">mpi_numpy_collectives.py</span></code> and run it with multiple processes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpi_numpy_collectives.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpi4py</span><span class="w"> </span><span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

<span class="c1"># Total number of elements in the big array (must be divisible by size)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10_000_000</span>

<span class="c1"># Only rank 0 creates the full array</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">big_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>  <span class="c1"># for simplicity, all ones</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">big_array</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># Each process will receive a chunk of this size</span>
<span class="n">local_N</span> <span class="o">=</span> <span class="n">N</span> <span class="o">//</span> <span class="n">size</span>

<span class="c1"># Allocate local buffer on each process</span>
<span class="n">local_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">local_N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>

<span class="c1"># Scatter the big array from root to all processes</span>
<span class="n">comm</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="p">[</span><span class="n">big_array</span><span class="p">,</span> <span class="n">MPI</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">],</span>       <span class="c1"># send buffer (only valid on root)</span>
    <span class="p">[</span><span class="n">local_array</span><span class="p">,</span> <span class="n">MPI</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">],</span>     <span class="c1"># receive buffer on all processes</span>
    <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Each process computes a local sum</span>
<span class="n">local_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">local_array</span><span class="p">)</span>

<span class="c1"># Reduce all local sums to a global sum on the root process</span>
<span class="n">global_sum</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">local_sum</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">MPI</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Global sum = </span><span class="si">{</span><span class="n">global_sum</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected   = </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Run the program using</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mpirun<span class="w"> </span>-n<span class="w"> </span><span class="m">4</span><span class="w"> </span>python<span class="w"> </span>mpi_numpy_collectives.py
</pre></div>
</div>
<p>Questions:</p>
<ol class="arabic simple">
<li><p>Which MPI calls distribute and collect data in this program?</p></li>
<li><p>Why is it necessary to preallocate local_array on every process?</p></li>
<li><p>What would happen if you used lowercase methods (scatter, reduce) instead of Scatter, Reduce?</p></li>
</ol>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-3">
<p class="admonition-title">Solution</p>
<p><em>Solution 1:</em> The MPI calls that distribute and collect data in this program are comm.Scatter() and comm.reduce().
Scatter divides the large NumPy array on the root process and sends chunks to all ranks, while Reduce collects the locally computed results and combines them (using MPI.SUM) into a single global result on the root process.</p>
<p><em>Solution 2:</em> It is necessary to preallocate local_array on every process because the uppercase MPI methods (Scatter, Gather, Reduce, etc.) work directly with memory buffers.
Each process must provide a fixed, correctly sized buffer so that MPI can write received data directly into it without additional memory allocation or copying.</p>
<p><em>Solution 3:</em> If lowercase methods (scatter, reduce) were used instead, MPI would serialize and deserialize the Python objects being communicated (using pickle).
This would make the program simpler but significantly slower for large numerical arrays, since it adds extra copying and memory overhead.
Using the uppercase buffer-based methods avoids this cost and achieves near-native C performance.</p>
</div>
</section>
<hr class="docutils" />
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Link to this heading">¶</a></h3>
<p><strong>mpi4py</strong> provides a simple yet powerful bridge between Python and the Message Passing Interface used in traditional HPC applications.<br />
Conceptually, it introduces the same communication paradigms used in compiled MPI programs but with Python’s expressiveness and interoperability.</p>
<div class="table-wrapper colwidths-auto docutils container">
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Concept</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Process</strong></p></td>
<td><p>Independent copy of the program with its own memory space</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Rank</strong></p></td>
<td><p>Identifier for each process within a communicator</p></td>
</tr>
<tr class="row-even"><td><p><strong>Point-to-Point</strong></p></td>
<td><p>Direct communication between pairs of processes</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Collective</strong></p></td>
<td><p>Group communication involving all processes</p></td>
</tr>
<tr class="row-even"><td><p><strong>NumPy Buffers</strong></p></td>
<td><p>Efficient memory sharing for large numerical data</p></td>
</tr>
</tbody>
</table>
</div>
<p>mpi4py allows Python users to write distributed parallel programs that scale from laptops to supercomputers, making it an invaluable tool for modern scientific computing.</p>
<hr class="docutils" />
<div class="admonition-keypoints keypoints admonition" id="keypoints-2">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>MPI creates multiple independent processes running the same program.</p></li>
<li><p>Point-to-point communication exchanges data directly between two processes.</p></li>
<li><p>Collective communication coordinates data exchange across many processes.</p></li>
<li><p>mpi4py integrates tightly with NumPy for efficient, zero-copy data transfers.</p></li>
<li><p>These concepts allow Python programs to scale effectively on HPC systems.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-profile"></span><section id="profiler">
<h2>Profiler<a class="headerlink" href="#profiler" title="Link to this heading">¶</a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Learn how to profile Python code using <code class="docutils literal notranslate"><span class="pre">cProfile</span></code></p></li>
<li><p>Learn how to visualise cProfile results using <code class="docutils literal notranslate"><span class="pre">SnakeViz</span></code></p></li>
<li><p>Examine the most most expensive function call via <code class="docutils literal notranslate"><span class="pre">line_profiler</span></code></p></li>
</ul>
</div>
<section id="deterministic-profilers-vs-sampling-profilers">
<h3>Deterministic profilers vs. sampling profilers<a class="headerlink" href="#deterministic-profilers-vs-sampling-profilers" title="Link to this heading">¶</a></h3>
<p>While <code class="docutils literal notranslate"><span class="pre">%timeit</span></code> can provide good benchmarking information on single lines or single functions,
larger codebases have more complex function hierarchies which require more sofisticated tools to
traverse properly.</p>
<p><strong>Deterministic profilers</strong> record every function call and event in the program,
logging the exact sequence and duration of events.</p>
<p>👍 <strong>Pros:</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  - Provides detailed information on the program&#39;s execution.
  
  - Deterministic: Captures exact call sequences and timings.
</pre></div>
</div>
<p>👎 <strong>Cons:</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  - Higher overhead, slowing down the program.
  
  - Can generate larger amount of data.
</pre></div>
</div>
<p><strong>Sampling profilers</strong> periodically samples the program’s state (where it is
and how much memory is used), providing a statistical view of where time is
spent.</p>
<p>👍 <strong>Pros:</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  - Lower overhead, as it doesn&#39;t track every event.
  
  - Scales better with larger programs.
</pre></div>
</div>
<p>👎 <strong>Cons:</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  - Less precise, potentially missing infrequent or short calls.
  
  - Provides an approximation rather than exact timing.
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><em>Deterministic profilers</em> are also called <em>tracing profilers</em>.</p>
</div>
<div class="admonition-discussion discussion important admonition" id="discussion-0">
<p class="admonition-title">Discussion</p>
<p><em>Analogy</em>: Imagine we want to optimize the Stockholm Länstrafik (SL) metro system.
We wish to detect bottlenecks in the system to improve the service and for this we have
asked few passengers to help us by tracking their journey.</p>
<ul class="simple">
<li><p><strong>Deterministic</strong>:
We follow every train and passenger, recording every stop
and delay. When passengers enter and exit the train, we record the exact time
and location.</p></li>
<li><p><strong>Sampling</strong>:
Every 5 minutes the phone notifies the passenger to note
down their current location. We then use this information to estimate
the most crowded stations and trains.</p></li>
</ul>
</div>
</section>
<section id="using-cprofile-to-investigate-performance">
<h3>Using <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> to investigate performance<a class="headerlink" href="#using-cprofile-to-investigate-performance" title="Link to this heading">¶</a></h3>
<p>Python comes with two <a class="reference external" href="https://docs.python.org/3/library/profile.html">built-in tools</a>
to profile code, which implement the same interface: <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> and <code class="docutils literal notranslate"><span class="pre">profile</span></code>.
These tools can help to identify performance bottlenecks in the code.</p>
<p>In this lesson, we will use <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> due to its smaller overhead (<code class="docutils literal notranslate"><span class="pre">profile</span></code>, on the other hand,
is more extensible). The standard syntax to call it is:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>cProfile<span class="w"> </span><span class="o">[</span>-o<span class="w"> </span>&lt;outputFile&gt;<span class="o">]</span><span class="w"> </span>&lt;python_module&gt;
</pre></div>
</div>
<p>By default, <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> writes the results to <code class="docutils literal notranslate"><span class="pre">stdout</span></code>, but the optional <code class="docutils literal notranslate"><span class="pre">-o</span></code> flag redirects
the output to file instead. A report can be generated using the <code class="docutils literal notranslate"><span class="pre">pstats</span></code> command.</p>
<div class="admonition-type-along type-along important admonition" id="type-along-0">
<p class="admonition-title">Type-Along</p>
<p>Let’s profile the <code class="docutils literal notranslate"><span class="pre">wordcount</span></code> script and write the results to a file.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Use the shell variant. The profiling output from Jupyter, although it seems to work, is hard to decipher.</p>
</div>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-SVB5dGhvbiAvIEp1cHl0ZXI=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tab" tabindex="0">IPython / Jupyter</button><button aria-controls="panel-0-VW5peCBTaGVsbA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tab" tabindex="-1">Unix Shell</button></div><div aria-labelledby="tab-0-SVB5dGhvbiAvIEp1cHl0ZXI=" class="sphinx-tabs-panel group-tab" id="panel-0-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tabpanel" tabindex="0"><p>The <code class="docutils literal notranslate"><span class="pre">%run</span></code> magic supports profiling out-of-the-box using the <code class="docutils literal notranslate"><span class="pre">-p</span></code> flag. The script can be run as:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="o">%</span><span class="k">run</span> -p -D wordcount.prof source/wordcount.py data/concat.txt processed_data/concat.dat
 
<span class="o">***</span> <span class="n">Profile</span> <span class="n">stats</span> <span class="n">marshalled</span> <span class="n">to</span> <span class="n">file</span> <span class="s1">&#39;wordcount.prof&#39;</span><span class="o">.</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-VW5peCBTaGVsbA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tabpanel" tabindex="0"><p>We can call <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>cProfile<span class="w"> </span>-o<span class="w"> </span>wordcount.prof<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/concat.txt<span class="w"> </span>processed_data/concat.dat
</pre></div>
</div>
<p>We can then generate a report using the <code class="docutils literal notranslate"><span class="pre">pstats</span></code> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>pstats<span class="w"> </span>wordcount.prof
<span class="c1"># Welcome to the profile statistics browser.</span>
<span class="c1"># wordcount.prof% sort tottime</span>
<span class="c1"># wordcount.prof% stats</span>
<span class="c1"># Wed Sep 25 11:52:27 2024    wordcount.prof</span>

<span class="c1">#          53473208 function calls in 8.410 seconds</span>

<span class="c1">#    Ordered by: internal time</span>

<span class="c1">#    ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span>
<span class="c1">#   1233410    4.151    0.000    7.204    0.000 source/wordcount.py:41(update_word_counts)</span>
<span class="c1">#  32068660    1.799    0.000    1.799    0.000 {method &#39;replace&#39; of &#39;str&#39; objects}</span>
<span class="c1">#   7747363    0.570    0.000    0.570    0.000 {method &#39;lower&#39; of &#39;str&#39; objects}</span>
<span class="c1">#   7747363    0.428    0.000    0.428    0.000 {method &#39;strip&#39; of &#39;str&#39; objects}</span>
<span class="c1">#   1530212    0.271    0.000    0.271    0.000 source/wordcount.py:23(&lt;genexpr&gt;)</span>
<span class="c1">#   1233411    0.256    0.000    0.256    0.000 {method &#39;split&#39; of &#39;str&#39; objects}</span>
<span class="c1">#         1    0.184    0.184    7.388    7.388 source/wordcount.py:59(calculate_word_counts)</span>
<span class="c1">#    382553    0.133    0.000    0.404    0.000 {method &#39;join&#39; of &#39;str&#39; objects}</span>
<span class="c1">#         1    0.126    0.126    0.580    0.580 source/wordcount.py:16(save_word_counts)</span>
<span class="c1"># ...</span>
</pre></div>
</div>
</div></div>
</div>
<div class="admonition-type-along type-along important admonition" id="type-along-1">
<p class="admonition-title">Type-Along</p>
<p>Let us consider the following code which simulates a random walk in one dimension.
Save it as <code class="docutils literal notranslate"><span class="pre">walk.py</span></code> or download it from <code class="docutils literal notranslate"><span class="pre">FIXME:</span> <span class="pre">here</span> <span class="pre">&lt;example/walk.py&gt;</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;A 1-D random walk.</span>

<span class="sd">See also:</span>
<span class="sd">- https://lectures.scientific-python.org/intro/numpy/auto_examples/plot_randomwalk.html</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>


<span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">():</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="o">-</span><span class="mf">1.0</span>


<span class="k">def</span><span class="w"> </span><span class="nf">walk</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dx</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The for-loop version.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n: int</span>
<span class="sd">        Number of time steps</span>

<span class="sd">    dx: float</span>
<span class="sd">        Step size. Default step size is unity.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">x_new</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">*</span> <span class="n">step</span><span class="p">()</span>
        <span class="n">xs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_new</span>

    <span class="k">return</span> <span class="n">xs</span>


<span class="k">def</span><span class="w"> </span><span class="nf">walk_vec</span><span class="p">(</span><span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dx</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The vectorized version of :func:`walk` using numpy functions.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">counts</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">n</span><span class="p">]))</span>

    <span class="c1"># steps = np.random.choice([1, -1], size=n)</span>

    <span class="n">dx_steps</span> <span class="o">=</span> <span class="n">dx</span> <span class="o">*</span> <span class="n">steps</span>

    <span class="c1"># set initial condition to zero</span>
    <span class="n">dx_steps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># use cumulative sum to replicate time evolution of position x</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dx_steps</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">xs</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">1_000_000</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">walk</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">walk_vec</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

</pre></div>
</div>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-SVB5dGhvbiAvIEp1cHl0ZXI=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tab" tabindex="0">IPython / Jupyter</button><button aria-controls="panel-1-VW5peCBTaGVsbA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tab" tabindex="-1">Unix Shell</button></div><div aria-labelledby="tab-1-SVB5dGhvbiAvIEp1cHl0ZXI=" class="sphinx-tabs-panel group-tab" id="panel-1-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tabpanel" tabindex="0"><p>The <code class="docutils literal notranslate"><span class="pre">%run</span></code> magic supports profiling out-of-the-box using the <code class="docutils literal notranslate"><span class="pre">-p</span></code> flag. The script can be run as:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="o">%</span><span class="k">run</span> -p -D walk.prof walk.py
 
<span class="o">***</span> <span class="n">Profile</span> <span class="n">stats</span> <span class="n">marshalled</span> <span class="n">to</span> <span class="n">file</span> <span class="s1">&#39;walk.prof&#39;</span><span class="o">.</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-VW5peCBTaGVsbA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tabpanel" tabindex="0"><p>We can call <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>cProfile<span class="w"> </span>-o<span class="w"> </span>walk.prof<span class="w"> </span>walk.py
</pre></div>
</div>
<p>We can then generate a report using the <a class="reference external" href="https://docs.python.org/3/library/profile.html#module-pstats">profile pstats module</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>pstats<span class="w"> </span>walk.prof
<span class="c1"># Welcome to the profile statistics browser.</span>
<span class="c1"># walk.prof% sort tottime</span>
<span class="c1"># walk.prof% stats</span>
<span class="c1"># Wed Sep 25 11:52:27 2024    walk.prof</span>
</pre></div>
</div>
</div></div>
</div>
<div class="admonition-discussion discussion important admonition" id="discussion-1">
<p class="admonition-title">Discussion</p>
<p>Profiling introduces a non-negligible overhead on the code being executed. Thus, the absolute values
for time being spent in each function should be taken with a grain of salt. The real objective lies in understanding
the <em>relative</em> amount of time spent in each function call.</p>
</div>
</section>
<section id="using-snakeviz-to-visualise-performance-reports">
<h3>Using SnakeViz to visualise performance reports<a class="headerlink" href="#using-snakeviz-to-visualise-performance-reports" title="Link to this heading">¶</a></h3>
<p><a class="reference external" href="https://jiffyclub.github.io/snakeviz/">SnakeViz</a> is a browser-based visualiser of
performance reports generated by <code class="docutils literal notranslate"><span class="pre">cProfile</span></code>. It is already included among the
dependecies installed in this virtual/Conda environment.</p>
<div class="admonition-type-along type-along important admonition" id="type-along-2">
<p class="admonition-title">Type-Along</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-SVB5dGhvbiAvIEp1cHl0ZXI=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-2-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tab" tabindex="0">IPython / Jupyter</button><button aria-controls="panel-2-VW5peCBTaGVsbA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tab" tabindex="-1">Unix Shell</button></div><div aria-labelledby="tab-2-SVB5dGhvbiAvIEp1cHl0ZXI=" class="sphinx-tabs-panel group-tab" id="panel-2-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tabpanel" tabindex="0"><p>SnakeViz has a IPython magic to profile and open a browser directly. To use it, we just
need to load the relevant extension and run it:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="o">%</span><span class="k">load_ext</span> snakeviz
<span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="o">%</span><span class="k">snakeviz</span> wordcount.word_count(&quot;data/concat.txt&quot;, &quot;processed_data/concat.dat&quot;, 1)
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This will run only if the source IPython instance has access to a local web browser.
This also means that, e.g., if you are on Windows and following the tutorial in WSL,
this will <code class="docutils literal notranslate"><span class="pre">not</span></code> work.</p>
</div>
</div><div aria-labelledby="tab-2-VW5peCBTaGVsbA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tabpanel" tabindex="0"><p>We can run SnakeViz as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>snakeviz<span class="w"> </span>wordcount.prof<span class="w"> </span>--server
</pre></div>
</div>
</div></div>
</div>
<p>The output will contain a clickable link containing the visualisation.</p>
<p><img alt="SnakeViz output" src="_images/snakeviz.png" /></p>
<p>Based on the output, we can clearly see that the <code class="docutils literal notranslate"><span class="pre">update_word_counts()</span></code> function
is where most of the runtime of the script is spent.</p>
</section>
<section id="using-line-profiler-to-inspect-the-expensive-function">
<h3>Using <code class="docutils literal notranslate"><span class="pre">line_profiler</span></code> to inspect the expensive function<a class="headerlink" href="#using-line-profiler-to-inspect-the-expensive-function" title="Link to this heading">¶</a></h3>
<p>Once the main performance-intensive function is identified, we can further examine it
to find bottlenecks. This can be done using the <code class="docutils literal notranslate"><span class="pre">line_profiler</span></code> tool, which returns a line-by-line
breakdown of where time is spent.</p>
<div class="admonition-type-along type-along important admonition" id="type-along-3">
<p class="admonition-title">Type-Along</p>
<p>Let’s profile the <code class="docutils literal notranslate"><span class="pre">wordcount</span></code> script and write the results to a file.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-SVB5dGhvbiAvIEp1cHl0ZXI=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-3-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tab" tabindex="0">IPython / Jupyter</button><button aria-controls="panel-3-VW5peCBTaGVsbA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-3-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tab" tabindex="-1">Unix Shell</button></div><div aria-labelledby="tab-3-SVB5dGhvbiAvIEp1cHl0ZXI=" class="sphinx-tabs-panel group-tab" id="panel-3-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tabpanel" tabindex="0"><p>The <code class="docutils literal notranslate"><span class="pre">line_profiler</span></code> package provides a magic to be used in IPython. First, the
magic needs to be loaded:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="o">%</span><span class="k">load_ext</span> line_profiler
</pre></div>
</div>
<p>The script can be run with the <code class="docutils literal notranslate"><span class="pre">%lprun</span></code> magic, whose syntax is very close to the <code class="docutils literal notranslate"><span class="pre">%run</span></code>
introduced above. Notice that we have to explicitly mention which functions we want to step through
line by line:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="o">%</span><span class="k">lprun</span> -f wordcount.update_word_counts wordcount.word_count(&quot;data/concat.txt&quot;, &quot;processed_data/concat.dat&quot;, 1)
</pre></div>
</div>
</div><div aria-labelledby="tab-3-VW5peCBTaGVsbA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-3-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tabpanel" tabindex="0"><p>To use <code class="docutils literal notranslate"><span class="pre">line_profiler</span></code> from the command line, the functions to be profiled need to be explicitly marked.
For this reason, we need to import the relevant decorator at the beginning of the <code class="docutils literal notranslate"><span class="pre">wordcount.py</span></code> script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">line_profiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">profile</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The tool will also work without the import</p>
</div>
<p>We can now mark the <code class="docutils literal notranslate"><span class="pre">update_word_counts</span></code> function with the <code class="docutils literal notranslate"><span class="pre">&#64;profile</span></code> decorator:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@profile</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_word_counts</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
</pre></div>
</div>
<p>Profiling is performed with a script called <code class="docutils literal notranslate"><span class="pre">kernprof</span></code>. Its usage is the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kernprof -lvr source/wordcount.py data/concat.txt processed_data/concat.dat</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">-l</span></code> flag ensures that the function is profiled step-by-step, the <code class="docutils literal notranslate"><span class="pre">-v</span></code> flag
shows the result on stdout and the <code class="docutils literal notranslate"><span class="pre">-r</span></code> flag is used to have rich format on output.</p>
</div></div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Wrote profile results to wordcount.py.lprof</span>
<span class="go">Timer unit: 1e-06 s</span>

<span class="go">Total time: 12.2802 s</span>
<span class="go">File: source/wordcount.py</span>
<span class="go">Function: update_word_counts at line 40</span>

<span class="go">Line #      Hits         Time  Per Hit   % Time  Line Contents</span>
<span class="go">==============================================================</span>
<span class="go">    40                                           @profile</span>
<span class="go">    41                                           def update_word_counts(line, counts):</span>
<span class="go">    42                                               &quot;&quot;&quot;</span>
<span class="go">    43                                               Given a string, parse the string and update a dictionary of word</span>
<span class="go">    44                                               counts (mapping words to counts of their frequencies). DELIMITERS are</span>
<span class="go">    45                                               removed before the string is parsed. The function is case-insensitive</span>
<span class="go">    46                                               and words in the dictionary are in lower-case.</span>
<span class="go">    47                                               &quot;&quot;&quot;</span>
<span class="go">    48  33302070    2574252.9      0.1     21.0      for purge in DELIMITERS:</span>
<span class="go">    49  32068660    4405499.9      0.1     35.9          line = line.replace(purge, &quot; &quot;)</span>
<span class="go">    50   1233410     392268.8      0.3      3.2      words = line.split()</span>
<span class="go">    51   8980773     819407.4      0.1      6.7      for word in words:</span>
<span class="go">    52   7747363    1457841.0      0.2     11.9          word = word.lower().strip()</span>
<span class="go">    53   7747363    1355462.5      0.2     11.0          if word in counts:</span>
<span class="go">    54   7364810    1211000.7      0.2      9.9              counts[word] += 1</span>
<span class="go">    55                                                   else:</span>
<span class="go">    56    382553      64505.7      0.2      0.5              counts[word] = 1</span>
</pre></div>
</div>
<p>Based on the output, we can conclude that most of the time is spent replacing delimiters.</p>
</div>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">cProfile</span></code> module can provide information on how costly each function call is.</p></li>
<li><p>Profile reports can be inspected using the <code class="docutils literal notranslate"><span class="pre">pstats</span></code> tool in tabular form or with SnakeViz
for a graphical visualisation</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">line_profiler</span></code> tool can be used to inspect line-by-line performance overhead.</p></li>
</ul>
</div>
</section>
</section>
<span id="document-benchmark"></span><section id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Link to this heading">¶</a></h2>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Introduce the example problem</p></li>
<li><p>Preparing the system for benchmarking using <code class="docutils literal notranslate"><span class="pre">pyperf</span></code></p></li>
<li><p>Learn how to runing benchmarks using <code class="docutils literal notranslate"><span class="pre">time</span></code>, <code class="docutils literal notranslate"><span class="pre">timeit</span></code> and <code class="docutils literal notranslate"><span class="pre">pyperf</span> <span class="pre">timeit</span></code></p></li>
</ul>
</div>
<section id="the-problem-word-count-hpda">
<h3>The problem: word-count-hpda<a class="headerlink" href="#the-problem-word-count-hpda" title="Link to this heading">¶</a></h3>
<p><img alt="word-count schematic" src="img/arrows.png" /></p>
<p>In this episode, we will use an
<a class="reference external" href="https://github.com/ENCCS/word-count-hpda">example project</a>
which finds most frequent words in books and plots the result
from those statistics. The project contains a
script <code class="docutils literal notranslate"><span class="pre">source/wordcount.py</span></code> which is executed to analyze word
frequencies from some books. The books are saved in plain-text format
in the <a class="reference external" href="https://github.com/ENCCS/word-count-hpda/tree/main/data">data</a> directory.</p>
<p>For example to run this code for one book, <em>pg99.txt</em></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/ENCCS/word-count-hpda.git
<span class="gp">$ </span><span class="nb">cd</span><span class="w"> </span>word-count-hpda<span class="w"> </span>
<span class="gp">$ </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/pg99.txt<span class="w"> </span>processed_data/pg99.dat
<span class="gp">$ </span>python<span class="w"> </span>source/plotcount.py<span class="w"> </span>processed_data/pg99.dat<span class="w"> </span>results/pg99.png
</pre></div>
</div>
</section>
<section id="preparation-use-pyperf-to-tune-your-system">
<h3>Preparation: Use <code class="docutils literal notranslate"><span class="pre">pyperf</span></code> to tune your system<a class="headerlink" href="#preparation-use-pyperf-to-tune-your-system" title="Link to this heading">¶</a></h3>
<p>Most personal laptops would be running in a power-saver / balanced power management mode.
This would include that the system has a scaling governor which can change
the CPU clock frequency on demand, among other things. This can cause <strong>jitter</strong>
which means that benchmarks are not reproducible enough and are less reliable.</p>
<p>In order to improve reliability of your benchmarks consider running the following</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It requires admin / root privileges.</p>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp"># </span>python<span class="w"> </span>-m<span class="w"> </span>pyperf<span class="w"> </span>system<span class="w"> </span>tune
</pre></div>
</div>
<p>When you are done with the lesson, you can run <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">pyperf</span> <span class="pre">system</span> <span class="pre">reset</span></code> or
restart the computer to go back to your default CPU settings.</p>
<section id="see-also">
<h4>See also<a class="headerlink" href="#see-also" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://pyperf.readthedocs.io/en/latest/system.html#operations-and-checks-of-the-pyperf-system-command">https://pyperf.readthedocs.io/en/latest/system.html#operations-and-checks-of-the-pyperf-system-command</a></p></li>
<li><p><a class="reference external" href="https://pyperf.readthedocs.io/en/latest/run_benchmark.html#how-to-get-reproducible-benchmark-results">https://pyperf.readthedocs.io/en/latest/run_benchmark.html#how-to-get-reproducible-benchmark-results</a></p></li>
<li><p><a class="reference external" href="https://pyperformance.readthedocs.io/usage.html#how-to-get-stable-benchmarks">https://pyperformance.readthedocs.io/usage.html#how-to-get-stable-benchmarks</a></p></li>
</ul>
</section>
</section>
<section id="benchmark-using-time">
<h3>Benchmark using <code class="docutils literal notranslate"><span class="pre">time</span></code><a class="headerlink" href="#benchmark-using-time" title="Link to this heading">¶</a></h3>
<p>In order to observe the cost of computation, we need to choose a
sufficiently large input data file and time the computation. We can
do that by concatenating all the books into a single input file
approximately 45 MB in size.</p>
<div class="admonition-type-along type-along important admonition" id="type-along-0">
<p class="admonition-title">Type-Along</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-SVB5dGhvbiAvIEp1cHl0ZXI=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-0-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tab" tabindex="0">IPython / Jupyter</button><button aria-controls="panel-0-VW5peCBTaGVsbA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-0-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tab" tabindex="-1">Unix Shell</button></div><div aria-labelledby="tab-0-SVB5dGhvbiAvIEp1cHl0ZXI=" class="sphinx-tabs-panel group-tab" id="panel-0-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tabpanel" tabindex="0"><p>Copy the following script.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">fileinput</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="n">files</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;pg*.txt&quot;</span><span class="p">)</span>
<span class="n">file_concat</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;concat.txt&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="p">(</span>
    <span class="n">fileinput</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="n">files</span><span class="p">)</span> <span class="k">as</span> <span class="n">file_in</span><span class="p">,</span>
    <span class="n">file_concat</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file_out</span>
<span class="p">):</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">file_in</span><span class="p">:</span>
        <span class="n">file_out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</pre></div>
</div>
<p>Open an IPython console or Jupyterlab, with <code class="docutils literal notranslate"><span class="pre">word-count-hpda</span></code> as the
current working directory (you can also use <code class="docutils literal notranslate"><span class="pre">%cd</span></code> inside IPython
to change the directory).</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">paste</span>

<span class="o">%</span><span class="k">ls</span> -lh data/concat.txt

<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">wordcount</span>

<span class="o">%</span><span class="k">time</span> wordcount.word_count(&quot;data/concat.txt&quot;, &quot;processed_data/concat.dat&quot;, 1)
</pre></div>
</div>
</div><div aria-labelledby="tab-0-VW5peCBTaGVsbA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-0-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>data/pg*.txt<span class="w"> </span>&gt;<span class="w"> </span>data/concat.txt
<span class="gp">$ </span>ls<span class="w"> </span>-lh<span class="w"> </span>data/concat.txt
<span class="gp">$ </span><span class="nb">time</span><span class="w"> </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/concat.txt<span class="w"> </span>processed_data/concat.dat
</pre></div>
</div>
</div></div>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-SVB5dGhvbiAvIEp1cHl0ZXI=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-1-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tab" tabindex="0">IPython / Jupyter</button><button aria-controls="panel-1-VW5peCBTaGVsbA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-1-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tab" tabindex="-1">Unix Shell</button></div><div aria-labelledby="tab-1-SVB5dGhvbiAvIEp1cHl0ZXI=" class="sphinx-tabs-panel group-tab" id="panel-1-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="o">%</span><span class="k">paste</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">fileinput</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="n">files</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;pg*.txt&quot;</span><span class="p">)</span>
<span class="n">file_concat</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;concat.txt&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="p">(</span>
    <span class="n">fileinput</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="n">files</span><span class="p">)</span> <span class="k">as</span> <span class="n">file_in</span><span class="p">,</span>
    <span class="n">file_concat</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file_out</span>
<span class="p">):</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">file_in</span><span class="p">:</span>
        <span class="n">file_out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
<span class="c1">## -- End pasted text --</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="o">%</span><span class="k">ls</span> -lh data/concat.txt
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="n">ashwinmo</span> <span class="n">ashwinmo</span> <span class="mi">45</span><span class="n">M</span> <span class="n">sep</span> <span class="mi">24</span> <span class="mi">14</span><span class="p">:</span><span class="mi">54</span> <span class="n">data</span><span class="o">/</span><span class="n">concat</span><span class="o">.</span><span class="n">txt</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
   <span class="o">...</span><span class="p">:</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="kn">import</span><span class="w"> </span><span class="nn">wordcount</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="o">%</span><span class="k">time</span> wordcount.word_count(&quot;data/concat.txt&quot;, &quot;processed_data/concat.dat&quot;, 1)
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">2.64</span> <span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">146</span> <span class="n">ms</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">2.79</span> <span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">2.8</span> <span class="n">s</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-VW5peCBTaGVsbA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-1-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tabpanel" tabindex="0"><div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>cat<span class="w"> </span>data/pg*.txt<span class="w"> </span>&gt;<span class="w"> </span>data/concat.txt
<span class="gp">$ </span>ls<span class="w"> </span>-lh<span class="w"> </span>data/concat.txt
<span class="go">-rw-rw-r-- 1 ashwinmo ashwinmo 46M sep 24 14:58 data/concat.txt</span>
<span class="gp">$ </span><span class="nb">time</span><span class="w"> </span>python<span class="w"> </span>source/wordcount.py<span class="w"> </span>data/concat.txt<span class="w"> </span>processed_data/concat.dat

<span class="go">real    0m2,826s</span>
<span class="go">user    0m2,645s</span>
<span class="go">sys     0m0,180s</span>
</pre></div>
</div>
</div></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>What are the implications of this small benchmark test?</p>
<p>It takes a few seconds to analyze a 45 MB file. Imagine that you are
working in a library and you are tasked with running this on several
terabytes of data.</p>
<ul class="simple">
<li><p>10 TB = 10 000 000 MB</p></li>
<li><p>Current processing speed = 45 MB / 2.8 s ~ 16 MB/s</p></li>
<li><p>Estimated time = 10 000 000 / 16 = 625 000 s = 7.2 days</p></li>
</ul>
<p>Then the same script would take days to complete!</p>
</div>
</section>
<section id="benchmark-using-timeit">
<h3>Benchmark using <code class="docutils literal notranslate"><span class="pre">timeit</span></code><a class="headerlink" href="#benchmark-using-timeit" title="Link to this heading">¶</a></h3>
<p>If you run the <code class="docutils literal notranslate"><span class="pre">%time</span></code> magic / <code class="docutils literal notranslate"><span class="pre">time</span></code> command again, you will notice
that the results vary a bit. To get a <strong>reliable</strong> answer we should repeat
the benchmark several times using <a class="reference external" href="https://docs.python.org/library/timeit.html"><code class="docutils literal notranslate"><span class="pre">timeit</span></code></a>. <a class="reference external" href="https://docs.python.org/library/timeit.html"><code class="docutils literal notranslate"><span class="pre">timeit</span></code></a> is part of
the Python standard library and it can be imported in a Python script
or used via a command-line interface.</p>
<p>If you’re using IPython / Jupyter notebook, the best choice will be
to use the <code class="docutils literal notranslate"><span class="pre">%timeit</span></code> magic.</p>
<p>As an example, here we benchmark the Numpy array:</p>
<div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="o">%</span><span class="k">timeit</span> a ** 2
<span class="c1"># 1.4 µs ± 25.1 ns per loop</span>
</pre></div>
</div>
<p>We could do the same for the <code class="docutils literal notranslate"><span class="pre">word_count</span></code> function.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-SVB5dGhvbiAvIEp1cHl0ZXI=" aria-selected="true" class="sphinx-tabs-tab group-tab" id="tab-2-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tab" tabindex="0">IPython / Jupyter</button><button aria-controls="panel-2-VW5peCBTaGVsbA==" aria-selected="false" class="sphinx-tabs-tab group-tab" id="tab-2-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tab" tabindex="-1">Unix Shell</button></div><div aria-labelledby="tab-2-SVB5dGhvbiAvIEp1cHl0ZXI=" class="sphinx-tabs-panel group-tab" id="panel-2-SVB5dGhvbiAvIEp1cHl0ZXI=" name="SVB5dGhvbiAvIEp1cHl0ZXI=" role="tabpanel" tabindex="0"><div class="highlight-ipython notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="p">[</span><span class="mi">6</span><span class="p">]:</span> <span class="o">%</span><span class="k">timeit</span> wordcount.word_count(&quot;data/concat.txt&quot;, &quot;processed_data/concat.dat&quot;, 1)
<span class="c1"># 2.81 s ± 12.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-VW5peCBTaGVsbA==" class="sphinx-tabs-panel group-tab" hidden="true" id="panel-2-VW5peCBTaGVsbA==" name="VW5peCBTaGVsbA==" role="tabpanel" tabindex="0"><p>We could use <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">timeit</span></code> which is the CLI interface of the standard library module <code class="docutils literal notranslate"><span class="pre">timeit</span></code>,</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span><span class="nb">source</span>
<span class="gp">$ </span>python<span class="w"> </span>-m<span class="w"> </span>timeit<span class="w"> </span>--setup<span class="w"> </span><span class="s1">&#39;import wordcount&#39;</span><span class="w"> </span><span class="s1">&#39;wordcount.word_count(&quot;data/concat.txt&quot;, &quot;processed_data/concat.dat&quot;, 1)&#39;</span>
<span class="go">1 loop, best of 5: 2.75 sec per loop</span>
</pre></div>
</div>
<p>or an even better alternative is using <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">pyperf</span> <span class="pre">timeit</span></code></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nb">export</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span><span class="nb">source</span>
<span class="gp">$ </span>python<span class="w"> </span>-m<span class="w"> </span>pyperf<span class="w"> </span>timeit<span class="w"> </span>--fast<span class="w"> </span>--setup<span class="w"> </span><span class="s1">&#39;import wordcount&#39;</span><span class="w"> </span><span class="s1">&#39;wordcount.word_count(&quot;data/concat.txt&quot;, &quot;processed_data/concat.dat&quot;, 1)&#39;</span>
<span class="go">...........</span>
<span class="go">Mean +- std dev: 2.72 sec +- 0.22 sec</span>
</pre></div>
</div>
</div></div>
<p>Notice that the output reports the <strong>arithmetic mean and standard deviation</strong> of timings. This is a good choice, since it means that <strong>outliers and temporary spikes in results are not automatically removed</strong>, which could be as a result of:</p>
<ul class="simple">
<li><p>garbage collection</p></li>
<li><p>JIT compilation</p></li>
<li><p>CPU or memory resource limitations</p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pyperf</span></code> can be used to tune the system</p></li>
<li><p>We understood the use of <code class="docutils literal notranslate"><span class="pre">time</span></code> and <code class="docutils literal notranslate"><span class="pre">timeit</span></code> to create benchmarks</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">time</span></code> is faster, since it is executed only once</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timeit</span></code> is more reliable, since it collects statistics</p></li>
</ul>
</div>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-quick-reference"></span><section id="quick-reference">
<h2>Quick Reference<a class="headerlink" href="#quick-reference" title="Link to this heading">¶</a></h2>
</section>
<span id="document-guide"></span><section id="instructor-s-guide">
<h2>Instructor’s guide<a class="headerlink" href="#instructor-s-guide" title="Link to this heading">¶</a></h2>
<section id="why-we-teach-this-lesson">
<h3>Why we teach this lesson<a class="headerlink" href="#why-we-teach-this-lesson" title="Link to this heading">¶</a></h3>
</section>
<section id="intended-learning-outcomes">
<h3>Intended learning outcomes<a class="headerlink" href="#intended-learning-outcomes" title="Link to this heading">¶</a></h3>
</section>
<section id="timing">
<h3>Timing<a class="headerlink" href="#timing" title="Link to this heading">¶</a></h3>
</section>
<section id="preparing-exercises">
<h3>Preparing exercises<a class="headerlink" href="#preparing-exercises" title="Link to this heading">¶</a></h3>
<p>e.g. what to do the day before to set up common repositories.</p>
</section>
<section id="other-practical-aspects">
<h3>Other practical aspects<a class="headerlink" href="#other-practical-aspects" title="Link to this heading">¶</a></h3>
</section>
<section id="interesting-questions-you-might-get">
<h3>Interesting questions you might get<a class="headerlink" href="#interesting-questions-you-might-get" title="Link to this heading">¶</a></h3>
</section>
<section id="typical-pitfalls">
<h3>Typical pitfalls<a class="headerlink" href="#typical-pitfalls" title="Link to this heading">¶</a></h3>
</section>
</section>
</div>
<section id="learning-outcomes">
<h2>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Link to this heading">¶</a></h2>
<p>FIXME</p>
<p>This material is for …</p>
<p>By the end of this module, learners should:</p>
<ul class="simple">
<li><p>…</p></li>
<li><p>…</p></li>
</ul>
</section>
<section id="see-also">
<h2>See also<a class="headerlink" href="#see-also" title="Link to this heading">¶</a></h2>
<div class="warning admonition">
<p class="admonition-title">Credit</p>
<p>FIXME</p>
<p>Don’t forget to check out additional course materials from …</p>
</div>
<div class="attention admonition">
<p class="admonition-title">License</p>
<div class="attention dropdown admonition">
<p class="admonition-title">CC BY-SA for media and pedagogical material</p>
<p>Copyright © 2025 XXX. This material is released by XXX under the Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0).</p>
<p><strong>Canonical URL</strong>: <a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0/">https://creativecommons.org/licenses/by-sa/4.0/</a></p>
<p><a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0/legalcode.en">See the legal code</a></p>
<p class="rubric" id="you-are-free-to">You are free to</p>
<ol class="arabic simple">
<li><p><strong>Share</strong> — copy and redistribute the material in any medium or format for any purpose, even commercially.</p></li>
<li><p><strong>Adapt</strong> — remix, transform, and build upon the material for any purpose, even commercially.</p></li>
<li><p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p></li>
</ol>
<p class="rubric" id="under-the-following-terms">Under the following terms</p>
<ol class="arabic simple">
<li><p><strong>Attribution</strong> — You must give <a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0/#ref-appropriate-credit">appropriate credit</a> , provide a link to the license, and <a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0/#ref-indicate-changes">indicate if changes were made</a> . You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</p></li>
<li><p><strong>ShareAlike</strong> — If you remix, transform, or build upon the material, you must distribute your contributions under the <a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0/#ref-same-license">same license</a> as the original.</p></li>
<li><p><strong>No additional restrictions</strong> — You may not apply legal terms or <a class="reference external" href="https://creativecommons.org/licenses/by-sa/4.0/#ref-technological-measures">technological measures</a> that legally restrict others from doing anything the license permits.</p></li>
</ol>
<p class="rubric" id="notices">Notices</p>
<p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/deed.en#ref-exception-or-limitation">exception or limitation</a> .</p>
<p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as <a class="reference external" href="https://creativecommons.org/licenses/by/4.0/deed.en#ref-publicity-privacy-or-moral-rights">publicity, privacy, or moral rights</a> may limit how you use the material.</p>
<p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>
</div>
<div class="attention dropdown admonition">
<p class="admonition-title">MIT for source code and code snippets</p>
<p>MIT License</p>
<p>Copyright (c) 2025, ENCCS project, The contributors</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, ENCCS, The contributors
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/ENCCS/python-for-hpc" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-accel-cython">Cython</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-cupy">CuPy</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-intohpc">Introduction to HPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-mpi4py">Introduction to MPI with Python (mpi4py)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-profile">Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-benchmark">Benchmark</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="#document-quick-reference">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="#document-guide">Instructor’s guide</a></li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=d6d90d09"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=35a8b989"></script>
    <script src="_static/minipres.js?v=a0d29692"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/tabs.js?v=3030b3cb"></script>
    </body>
</html>